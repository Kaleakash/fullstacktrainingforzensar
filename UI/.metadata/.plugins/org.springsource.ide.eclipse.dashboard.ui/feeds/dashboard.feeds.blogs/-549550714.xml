<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Spring</title>
  <link rel="alternate" href="https://spring.io/blog" />
  <link rel="self" href="https://spring.io/blog.atom" />
  <id>http://spring.io/blog.atom</id>
  <icon>https://spring.io/favicon.ico</icon>
  <updated>2021-02-05T04:24:00Z</updated>
  <entry>
    <title>A Bootiful Podcast:  RSocket legend and new Reactor team member Oleh Dokuka</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/04/a-bootiful-podcast-rsocket-legend-and-new-reactor-team-member-oleh-dokuka" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-05:4355</id>
    <updated>2021-02-05T04:24:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;A Bootiful Podcast&lt;/em&gt;! In this episode, &lt;a href="https://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to RSocket legend and new Reactor team member &lt;a href="https://twitter.com/OlehDokuka"&gt;Oleh Dokuka (@OlehDokuka)&lt;/a&gt; about RSocket routing, the RSocket broker, Netty, HTTP3 and Quick, the &lt;code&gt;RSocketClient&lt;/code&gt;, and so much more. &lt;/p&gt;
&lt;iframe title="RSocket legend and new Reactor team member Oleh Dokuka " height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/m4ht5-f9c3eb?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Demystifying Spring Cloud Stream producers with Apache Kafka partitions</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/03/demystifying-spring-cloud-stream-producers-with-apache-kafka-partitions" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Soby Chacko</name>
    </author>
    <id>tag:spring.io,2021-02-03:4352</id>
    <updated>2021-02-03T20:24:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we are taking a deeper look at writing a Spring Cloud Stream producer with Apache Kafka and how it handles native partitions in Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream has a middleware agnostic concept of partitions. Whenever possible, Spring Cloud Stream leverages the native partitioning capabilities of the middleware if it has such capabilities as in the case of Apache Kafka. This blog looks at how a Spring Cloud Stream developer handles partitions when writing a producer application that publishes data to Kafka. In a subsequent article, we will look at how consumers handle partitions in a Kafka based Spring Cloud Stream application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Partitions are the basic unit of scaling and parallelism in Apache Kafka. Using the right partitioning strategies allows your application to handle terabytes of data at scale with minimal latency. A Kafka producer can write to different partitions in parallel, which generally means that 	it can achieve higher levels of throughput. While partitioning has these obvious upsides, there are other various considerations one needs to carefully make. Within a partition itself, throughput may be further limited by factors such as batching size, compression algorithms used, type of acknowledgments, replication factor, etc. Further, having more partitions means more open file handles (because partitions map to a directory on the broker and each log segment within a partition needs an index file and a data file). There are plenty of resources available on the web on how to come up with the right number of partitions for a Kafka application, which you may want to get familiar with before deploying your Kafka based enterprise producer application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="spring-cloud-stream-provisioner-for-kafka-binder"&gt;&lt;a class="anchor" href="#spring-cloud-stream-provisioner-for-kafka-binder"&gt;&lt;/a&gt;Spring Cloud Stream Provisioner for Kafka binder&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream Kafka binder has a topic provisioner that handles the various application-level topic requirements. Among other things, creating and modifying the number of partitions is something that the provisioner is capable of doing. The Provisioner itself is not doing these operations but calls the right admin APIs from the Kafka cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are two scenarios that deal with topic creation that could come up with when writing a Spring Cloud Stream Kafka application in general. Most enterprises lock down access to the Kafka cluster and only an admin can make such operational changes as creating a topic, adding partitions, etc. In this scenario, the applications cannot directly create or modify topics. The other scenario is that the enterprise is pretty relaxed when it comes to giving access to the Kafka cluster in that the applications are free to create or modify the topics. Let’s consider a few of these things further.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-1-application-has-full-admin-privileges-on-the-kafka-cluster"&gt;&lt;a class="anchor" href="#scenario-1-application-has-full-admin-privileges-on-the-kafka-cluster"&gt;&lt;/a&gt;Scenario 1: Application has full admin privileges on the Kafka Cluster&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this scenario, the application has full admin access to the Kafka cluster. You are writing a Spring Cloud Stream producer that publishes messages to a Kafka topic. For the sake of our discussion, let’s assume that this topic is non-existent and your application will create it. You also want to make sure that the topic is provisioned with a certain number of partitions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are a couple of ways to tell Spring Cloud Stream, how many partitions you want the topic to be provisioned with. Each one has pros and cons. Let’s look at them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use a binder wide property to specify the partition count. Using this, any topic that you create will have the same partition count. If your application is creating multiple topics and they all want the same number of partitions, this is an ideal way to create partitions. The disadvantage of this approach is that this is non-configurable per-binding unless overridden. The property you use at the binder level is the following.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.kafka.binder.min-partition-count&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Another option is to have the partition count specified at the binding level. Using this approach, you can have multiple topics in the same application configured with different partition counts. The following is the property&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-count&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Given that the previous global property enforces a minimum (it could be larger), the larger of the two will take effect for a specific binding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If neither of the above options is used, then the topic will be created with the number of partitions based on the broker &lt;code&gt;num.partitions&lt;/code&gt; property (default: 1).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-2-kafka-cluster-is-locked-down-and-the-application-is-not-allowed-to-perform-any-admin-operations"&gt;&lt;a class="anchor" href="#scenario-2-kafka-cluster-is-locked-down-and-the-application-is-not-allowed-to-perform-any-admin-operations"&gt;&lt;/a&gt;Scenario 2: Kafka Cluster is locked down and the application is not allowed to perform any admin operations.&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this scenario, your options as an application developer are very limited. Since the Kafka cluster is locked down, the application will not be able to create or change existing topics. If the topic is not created beforehand, your application will throw an exception during startup and fail. In order to avoid this, you have to make sure that the topic is created with the right number of partitions and disable automatic topic provisioning using the binder property (spring.cloud.stream.kafka.binder.auto-create-topics set to false).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-3-application-has-full-admin-privileges-on-the-kafka-cluster-and-the-topic-already-exists-but-you-want-to-increase-the-partitions-next-time-the-application-starts"&gt;&lt;a class="anchor" href="#scenario-3-application-has-full-admin-privileges-on-the-kafka-cluster-and-the-topic-already-exists-but-you-want-to-increase-the-partitions-next-time-the-application-starts"&gt;&lt;/a&gt;Scenario 3: Application has full admin privileges on the Kafka Cluster and the topic already exists, but you want to increase the partitions next time the application starts.&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is possible. Let’s say that your topic is already provisioned with 64 partitions, now you want to double that to 128 due to some higher capacity requirements. You let the binder know that by using either of the properties discussed in scenario 1. (&lt;code&gt;spring.cloud.stream.kafka.binder.min-partition-count&lt;/code&gt; or &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-count&lt;/code&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this case, the binder detects that the topic already exists. If the topic’s current partition size is less than what is requested, then the binder checks for a property &lt;code&gt;spring.cloud.stream.kafka.binder.autoAddPartitions&lt;/code&gt;. By default, this is set to &lt;code&gt;false&lt;/code&gt;. So, if the application has a need for increasing the partitions, this has to be explicitly set to &lt;code&gt;true&lt;/code&gt;. If it is set to &lt;code&gt;true&lt;/code&gt;, the provisioner will request the Kafka admin API to increase the number of partitions. If it is not set to true and the new requested number of partitions is higher than the existing number of partitions, then in the case of producers, the binder will complain that it cannot tolerate the lower number of partitions on the broker and throw a provisioning exception. If this happens, you have to either increase the partitions manually or set the &lt;code&gt;autoAddPartitions&lt;/code&gt; property to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One thing to note in particular here is that the binder does not allow you to decrease the number of Kafka topic partitions through Spring Cloud Stream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Bear in mind that increasing or decreasing the partitions (using any mechanism) might break strict ordering within a partition (if that&amp;#8217;s a consideration), depending on your partitioning strategy (see below).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="selecting-a-partition"&gt;&lt;a class="anchor" href="#selecting-a-partition"&gt;&lt;/a&gt;Selecting a Partition&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we understand how topics are partitioned, we need to discuss how to select a partition for a particular record.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are three mechanisms to select the partition:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="native-kafka-partition-selection"&gt;&lt;a class="anchor" href="#native-kafka-partition-selection"&gt;&lt;/a&gt;Native Kafka Partition Selection&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To use native partitioning, configure a custom Partitioner, either at the binder level, using the &lt;code&gt;spring.cloud.stream.kafka.binder.producer-properties.partitioner.class&lt;/code&gt; property
or at the binding level, using the
&lt;code&gt;spring.cloud.stream.kafka.bindings.&amp;lt;binding&amp;gt;.producer.configuration.partitioner.class&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="directly-setting-the-partition-header"&gt;&lt;a class="anchor" href="#directly-setting-the-partition-header"&gt;&lt;/a&gt;Directly setting the partition header&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When using the default Kafka Partitioner, the application can directly set the &lt;code&gt;KafkaHeaders.PARTITION_ID&lt;/code&gt;  header to the desired partition.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="spring-cloud-stream-partition-selection"&gt;&lt;a class="anchor" href="#spring-cloud-stream-partition-selection"&gt;&lt;/a&gt;Spring Cloud Stream Partition Selection&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When using Spring Cloud Stream partitioning, leave the kafka partitioner to use its default partitioner, which will simply use the partition set in the producer record by the binder. In the following sections, we will see details of this support provided by Spring Cloud Stream.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="how-does-a-spring-cloud-stream-producer-determine-which-partition-to-assign"&gt;&lt;a class="anchor" href="#how-does-a-spring-cloud-stream-producer-determine-which-partition-to-assign"&gt;&lt;/a&gt;How does a Spring Cloud Stream producer determine which partition to assign?&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;How is it that the producer assigns records to the right partitions using Spring Cloud Stream? What are the controls available for doing so in Spring Cloud Stream? The remainder of this blog will focus on these questions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="deciding-on-a-partition-key"&gt;&lt;a class="anchor" href="#deciding-on-a-partition-key"&gt;&lt;/a&gt;Deciding on a partition key&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream provides two mechanisms for the application to decide on a partition key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="1-partition-key-expression"&gt;&lt;a class="anchor" href="#1-partition-key-expression"&gt;&lt;/a&gt;1. Partition key expression&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A simple approach is to provide the partition key as a SpEL expression property. Here is an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-key-expression: headers['partitionKey']&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Then your application, when publishing the message, can add a header called partitonKey. Spring Cloud Stream will use the value for this header when evaluating the above expression to assign a partition key. Here is an example producer code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;@Bean
public Supplier&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt; generate() {
  return () -&amp;gt; {
     String value = “random payload”;
    	return MessageBuilder.withPayload(value)
           .setHeader("partitionKey", value.length() % 4)
           .build();
  };
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="2-partition-key-extractor-strategy"&gt;&lt;a class="anchor" href="#2-partition-key-extractor-strategy"&gt;&lt;/a&gt;2. Partition key extractor strategy&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream provides an API called PartitionKeyExtractorStrategy which has a single method to implement - &lt;code&gt;Object extractKey(Message&amp;lt;?&amp;gt; message)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can implement this interface and configure it as a bean. Then provide a property &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.parition-key-extractor-name&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And then provide the bean name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you only have one such bean, then you can ignore providing this as a property. Spring Cloud Stream will simply pick this bean as the partition extractor strategy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Setting a key using a partition key extractor strategy is the default mechanism. Spring Cloud Stream will only look for the partition key expression if an extractor strategy is not given.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Please bear in mind that this partition key we discussed here may not be the same as the ultimate partition the record will land upon. For that we need to use a partition selector that is using this key.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="selecting-the-actual-partition"&gt;&lt;a class="anchor" href="#selecting-the-actual-partition"&gt;&lt;/a&gt;Selecting the actual partition&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We selected a partition key, now how does it select the actual partition on Kafka topic?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Ok, now we got Spring Cloud Stream to decide on a partition key to use. But, how about actually selecting the partition based on this key? Similar to the partition key selection options, Spring Cloud Stream provides two different mechanisms for selecting the partition with a given key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="1-use-a-partition-selector-strategy"&gt;&lt;a class="anchor" href="#1-use-a-partition-selector-strategy"&gt;&lt;/a&gt;1. Use a Partition Selector Strategy`&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once again, this is a functional interface with a single method - &lt;code&gt;int selectPartition(Object key, int partitionCount)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can implement this method and provide it as a bean. If you only have one such bean, you don’t need any additional property. If there are more than one, then you can define it per binding using the property &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.parition-selector-name&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="2-partition-selector-expression"&gt;&lt;a class="anchor" href="#2-partition-selector-expression"&gt;&lt;/a&gt;2. Partition Selector Expression&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don’t want to implement a partition selector strategy, you can also provide a SpEL expression that evaluates against the key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If neither of these options are provided, then Spring Cloud Stream will use a default Partition Selector Strategy which is based on taking the hashCode of the key and then doing a modulo operation with the total partition count on the topic. Unless you have sophisticated needs, this default strategy will work in most cases.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="why-is-the-binder-providing-two-different-abstractions"&gt;&lt;a class="anchor" href="#why-is-the-binder-providing-two-different-abstractions"&gt;&lt;/a&gt;Why is the binder providing two different abstractions?&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You might be wondering why we have these two different abstractions. First a partition key and then a partition selector. Partition key could be anything - for example, it could be an integer, a string (maybe a text with arbitrary length) or some other type. Partition selector will select a key based on the partition key expression. The selector also makes sure that the partition selected is bound within the available number of partitions. The default implementation does it by doing a modulo division of the hash code of the partition key and the total number of partitions. For this reason, when you have partitioning use cases like these, you must specify the &lt;code&gt;partittionCount&lt;/code&gt; property on the producer. In summary, &lt;code&gt;PartitionKey&lt;/code&gt; is a piece of data used by PartitionSelector to select the actual partition.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let’s take a concrete example. Assume that you are writing an application that deals with credit card transactions. This application uses the credit card number as the partition key - a long random number with x number of digits. Imagine that depending on the first 4 digits of the credit card, you want to send that transaction to a particular partition in the topic. How do you do that? First, you set your &lt;code&gt;partitionKeyExpression&lt;/code&gt; by parsing the card number to extract the first 4 digits (or provide a partition key extractor strategy). Then, you need to provide a partition selector strategy implementation in which, based on the key and the number of partitions, you select the key. If you don’t provide this or a partition key selector expression against the key, then the default partition selector strategy will select one for you. Say, your first 4 digits are 1234 and you have 10 partitions on the topic. Let’s say that the hash is computed as 1234 also. Then, this will land in partition &lt;code&gt;1234 % 10 = 4&lt;/code&gt;. If you rather want this transaction to come to partition 8 for whatever reason, then you have to explicitly implement that in partition selector strategy class or expression.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Following is a flow chart representation of how these two different layers fit together.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;span class="image"&gt;&lt;img src="https://github.com/spring-cloud/spring-cloud-stream-binder-kafka/raw/gh-pages/images/kafka-producer-partitions-blog.png" alt="kafka producer partitions blog"&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="confusion-between-partition-key-and-the-message-key"&gt;&lt;a class="anchor" href="#confusion-between-partition-key-and-the-message-key"&gt;&lt;/a&gt;Confusion between partition key and the message key&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Sometimes it is confusing to think through partition keys and the actual message keys going down the wire through the actual Kafka topic to be used on the Kafka record as the key. It is done through a different mechanism. The above partition key and the selector simply ensures that a partition key is chosen and based on that partition key, an actual partition is selected on the Kafka topic. But, how do you send a key with the record when producing? Here again, you can choose from two options. One is simply to attach a header into the outgoing message. Here is an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;@Bean Supplier&amp;lt;Message&amp;lt;String&amp;gt;&amp;gt; process() {
   return () -&amp;gt; MessageBuilder.withPayload("foo")
     .setHeader(KafkaHeaders.MESSAGE_KEY, "bar".getBytes()) .build(); }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can also use a message key SpEL expression on the Kafka binder as below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.kafka.binder.messageKeyExpression: headers['messageKey']&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Then attach this header on the outgoing message.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="some-caveats-to-keep-in-mind"&gt;&lt;a class="anchor" href="#some-caveats-to-keep-in-mind"&gt;&lt;/a&gt;Some caveats to keep in mind&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don’t provide a partition key expression or partition key extractor bean, then Spring Cloud Stream will completely stay out of the business of making any partition decision for you. In that case, if the topic has more than one partition, Kafka’s default partitioning mechanisms will be triggered. By default, Kafka uses a DefaultPartitioner, which if the message has a key (see above), then using the hash of this key for computing the partition. If the message does not have a key, then it will be assigned using a round robin strategy. Starting with Kafka client 2.4 onwards, there are some additional complexities to keep in mind. If the record doesn’t carry the partition information (the main discussion of this blog) or if the record is missing a key, then starting with Kafka 2.4, it will use sticky partitions instead of a round-robin strategy. In a nutshell, sticky partitions are used to minimize the latency by sticking the records to a partition or a group of partitions. For more information on sticky partitions, see KIP-480 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner" class="bare"&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="conclusion"&gt;&lt;a class="anchor" href="#conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we discussed how Spring Cloud Stream can help with dealing with Kafka partitions when writing a producer based application. We saw a number of ways Spring Cloud Stream gives controls to the application developer to configure the various nuances of partitions. We saw the differences between partition key, partition selector and message key. We discussed how message keys can be added to a Kafka record. Finally, we looked at how Spring Cloud Stream producers can completely stay out of the partitioning business and let Kafka tackle it directly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - February 2nd, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/02/this-week-in-spring-february-2nd-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-03:4351</id>
    <updated>2021-02-03T02:44:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! Can you believe we&amp;rsquo;re already square into the second month of 2021? We&amp;rsquo;re 1/12th of the way through the year already! IT&amp;rsquo;S ALL GOING SO QUICK! So, I won&amp;rsquo;t waste any further time, let&amp;rsquo;s get to the roundup! &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;This is a fantastic video by the legendary Brian Sam Boden on &lt;a href="https://www.youtube.com/watch?v=XJoJCMfCSTk&amp;feature=emb_title"&gt;&lt;em&gt;building a Spring Boot REST API powered by Redis, with a React front end: Part 1&lt;/em&gt; &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2021/02/02/2021-a-look-ahead-for-open-source-at-vmware/"&gt;2021: A Look Ahead for Open Source at VMware&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/28/a-bootiful-podcast-appdynamics-pavol-loffay"&gt;A Bootiful Podcast: Traceable&amp;rsquo;s Pavol Loffay, creator of the Hypertrace Java agent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/news/2021/01/graalvm-21-jvm-java/"&gt;GraalVM 21.0 Introduces a JVM Written in Java&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://medium.com/sipios/handle-r2dbc-in-spring-projects-fa96e65ca24d"&gt;Handle R2DBC in Spring Projects, &lt;/a&gt; an article by Thibault MONEGIER du SORBIER&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.meetup.com/seajug/events/276135388/"&gt;I&amp;rsquo;ll be speaking at the Seattle JUG Meetup on February 16th, 2021&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.oracle.com/developers/new-year-goodies-oracle-jdbc-21100-on-maven-central"&gt;New Year Goodies - Oracle JDBC 21.1.0.0 on Maven Central | Oracle Developers Blog&lt;/a&gt;. I linked to this because, at the bottom of the blog, they also mention that people can expect the reactive Oracle R2DBC driver soon, too! Huzzah!&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.vinsguru.com/rsocket-load-balancing-client-side/"&gt;RSocket Load Balancing - Client Side by Vinsguru&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/articles/running-axon-server-docker-kubernetes/?itm_campaign=rightbar_v2&amp;itm_source=infoq&amp;itm_medium=articles_link&amp;itm_content=link_text"&gt;Running Axon Server in Docker and Kubernetes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/27/spring-batch-on-kubernetes-efficient-batch-processing-at-scale"&gt;Spring Batch on Kubernetes: Efficient batch processing at scale&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/28/spring-cloud-2020-0-1-aka-ilford-is-available"&gt;Spring Cloud 2020.0.1 (aka Ilford) Is Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/01/spring-integration-aws-2-3-5-release-2-4-0-and-spring-cloud-stream-kinesis-binder-2-0-4-release-2-1-0-available"&gt;Spring Integration AWS 2.3.5.RELEASE &amp;amp; 2.4.0, and Spring Cloud Stream Kinesis Binder 2.0.4.RELEASE &amp;amp; 2.1.0 Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/01/ymnnalft-a-lightweight-sql-data-mapper-with-the-jdbctemplate"&gt;YMNNALFT: A lightweight SQL data mapper with the JdbcTemplate&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/27/ymnnalft-the-spring-utils-classes"&gt;YMNNALFT: The Spring Utils Classes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1354831588916305922"&gt;Last year Azure #Spring Cloud became Generally Available. Here&amp;rsquo;s what has changed since then! &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1356334244008611840"&gt;Apple announced M1, an impl of AArch64. #OpenJDK was ready for it; had been for 5 years. However there&amp;rsquo;s a layer that’s specific to each OS-CPU combination. However there&amp;rsquo;s a layer that’s specific to each OS-CPU combination. We had volunteers: Microsoft and Azul, who worked together. Microsoft also ported to Win/AArch64 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMware/status/1356739950620905472"&gt; Today, we’re excited to announce dates for VMware conferences slated for this year &amp;ndash; VMworld, CloudLIVE, Connect, and SpringOne! &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Integration AWS 2.3.5.RELEASE &amp; 2.4.0,  and Spring Cloud Stream Kinesis Binder 2.0.4.RELEASE &amp; 2.1.0 Available</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/01/spring-integration-aws-2-3-5-release-2-4-0-and-spring-cloud-stream-kinesis-binder-2-0-4-release-2-1-0-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Artem Bilan</name>
    </author>
    <id>tag:spring.io,2021-02-01:4350</id>
    <updated>2021-02-01T16:05:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Dear Spring Community,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Today it&amp;#8217;s my pleasure to announce releases of Spring Integration for Amazon Web Services extension versions &lt;code&gt;2.3.5.RELEASE&lt;/code&gt; &amp;amp; &lt;code&gt;2.4.0&lt;/code&gt;, and Spring Cloud Stream Binder for AWS Kinesis versions &lt;code&gt;2.0.4.RELEASE&lt;/code&gt; &amp;amp; &lt;code&gt;2.1.0&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;These releases can be downloaded from Maven Central, JCenter:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="groovy"&gt;compile "org.springframework.integration:spring-integration-aws:2.3.5.RELEASE"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don&amp;#8217;t use Kinesis Binder.
Or via Binder dependency:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="groovy"&gt;compile "org.springframework.cloud:spring-cloud-stream-binder-kinesis:2.0.4.RELEASE"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Mostly these versions have bug fixes and some community feedback refinements.
So, it is highly recommended to bump your projects to this latest versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The new minor versions (&lt;code&gt;spring-integration-aws:2.4.0&lt;/code&gt; &amp;amp; &lt;code&gt;spring-cloud-stream-binder-kinesis:2.1.0&lt;/code&gt;) have the same fixes content, but with an upgrade to the latest Spring Integration and Spring Cloud Stream versions for compatibility with the latest Spring Boot and Spring Cloud, respectively.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Many thanks to everyone from the Community for all the feedback and contribution to these projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Any feedback is welcome via all the available communication channels!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Integration for AWS resources:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-projects/spring-integration-aws"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-integration/blob/master/CONTRIBUTING.adoc"&gt;Contributing&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-integration"&gt;Help&lt;/a&gt; | &lt;a href="https://gitter.im/spring-projects/spring-integration"&gt;Chat&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream Binder for AWS Kinesis resources:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis/blob/master/spring-cloud-stream-binder-kinesis-docs/src/main/asciidoc/contributing.adoc"&gt;Contributing&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-cloud-stream"&gt;Help&lt;/a&gt; | &lt;a href="https://gitter.im/spring-projects/spring-cloud-stream"&gt;Chat&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT: A lightweight SQL data mapper with the JdbcTemplate</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/01/ymnnalft-a-lightweight-sql-data-mapper-with-the-jdbctemplate" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4324</id>
    <updated>2021-02-01T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;I think the first use I had for Spring, more than 15 years ago, was the &lt;code&gt;JdbcTemplate&lt;/code&gt;, which eliminated the eye-watering and verbose work of using JDBC directly. As you might know, JDBC stands for &amp;ldquo;Just Don&amp;rsquo;t Break, Compiler!&amp;rdquo; and was designed to test the JVM limit of 65535 bytes of bytecode per method by providing an API that consistently requires more lines of code than that to do even basic things. &lt;/p&gt;
&lt;p&gt;Thus just in. I&amp;rsquo;m being told that JDBC is, in fact, the Java Database Connectivity API. Moving on&amp;hellip; &lt;/p&gt;
&lt;p&gt;I couldn&amp;rsquo;t use Spring as a framework in the project at the time, but I &lt;em&gt;could&lt;/em&gt; bring in Spring as a sort of library. I brought it in initially to get access to the &lt;code&gt;JdbcTemplate&lt;/code&gt;, and the concept of the various &lt;code&gt;*Template&lt;/code&gt; objects as a whole. &lt;/p&gt;
&lt;p&gt;A template object is an excellent example of the inversion-of-control principle. You let the template object do 90% of the work and provide it with a callback to be invoked when the template needs your input on something. Templates invert the application flow; they do the tedious stuff and then involve you only when it&amp;rsquo;s time to do the thing you want to do. They&amp;rsquo;re kind of like &lt;em&gt;mini-frameworks&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;JdbcTemplate&lt;/code&gt; is one of the best-known templates in the Java ecosystem, and for a good reason. JDBC is a low-level API in the Java ecosystem for working with SQL databases. It&amp;rsquo;s powerful, and it has dominated for &lt;em&gt;decades&lt;/em&gt;. But it is, at the end of the day, &lt;em&gt;very&lt;/em&gt; low level. You&amp;rsquo;re not going to get very far writing this code yourself. &lt;/p&gt;
&lt;p&gt;The alternatives were brittle (at the time) technologies like Hibernate, Apache OJB, any of the various, mildly incompatible JDO implementations, iBatis, or - &lt;em&gt;gasp!&lt;/em&gt; - EJB 1.x or 2.x persistent entity beans. Most of these were way too top-heavy for the work I was trying to do. I loved iBatis (and continue to love its &lt;a href="http://mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/"&gt;successor MyBatis&lt;/a&gt;), but I found I could get far with just the &lt;code&gt;JdbcTemplate&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;JdbcTemplate&lt;/code&gt; is part of a rich class arrangement and various abstractions for working with SQL databases. Nowadays, there&amp;rsquo;s even a non-blocking, reactive alternative to JDBC available to the Spring developer: &lt;a href="https://R2DBC.io"&gt;R2DBC&lt;/a&gt;. Most data access logic today uses JDBC (indirectly, if nothing else), alas, so let&amp;rsquo;s look at an example of that. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
  &lt;p&gt;JDBC on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-jdbc&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
  &lt;li&gt;
  &lt;p&gt;H2 on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;com.h2database&lt;/code&gt; : &lt;code&gt;h2&lt;/code&gt; &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.data;&#xD;
&#xD;
import lombok.SneakyThrows;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.io.ClassPathResource;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.jdbc.core.JdbcTemplate;&#xD;
import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseBuilder;&#xD;
import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType;&#xD;
import org.springframework.util.FileCopyUtils;&#xD;
&#xD;
import javax.sql.DataSource;&#xD;
import java.io.InputStreamReader;&#xD;
import java.io.Reader;&#xD;
import java.util.List;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	DataSource dataSource() {&#xD;
		return new EmbeddedDatabaseBuilder().setType(EmbeddedDatabaseType.H2).build();&#xD;
	}&#xD;
&#xD;
	@SneakyThrows&#xD;
	private String loadSql() {&#xD;
		Resource resource = new ClassPathResource(&amp;quot;/initialization.sql&amp;quot;);&#xD;
		try (Reader r = new InputStreamReader(resource.getInputStream())) {&#xD;
			return FileCopyUtils.copyToString(r);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(DataSource dataSource) {&#xD;
		return event -&amp;gt; {&#xD;
			String sql = loadSql();&#xD;
			String[] names = new String[] { &amp;quot;Spencer&amp;quot;, &amp;quot;Violetta&amp;quot;, &amp;quot;Madhura&amp;quot;, &amp;quot;Yuxin&amp;quot;, &amp;quot;Stéphane&amp;quot;, &amp;quot;Dr. Syer&amp;quot; };&#xD;
			JdbcTemplate template = new JdbcTemplate(dataSource);&#xD;
			template.execute(sql);&#xD;
			for (var name : names) {&#xD;
				template.update(&amp;quot;insert into CUSTOMER(name) values(?)&amp;quot;, name);&#xD;
			}&#xD;
			List&amp;lt;Customer&amp;gt; results = template.query(&amp;quot;select * from CUSTOMER&amp;quot;,&#xD;
					(resultSet, i) -&amp;gt; new Customer(resultSet.getInt(&amp;quot;id&amp;quot;), resultSet.getString(&amp;quot;name&amp;quot;)));&#xD;
			results.forEach(System.out::println);&#xD;
		};&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don&amp;rsquo;t mind rolling up your sleeves and slinging a little SQL (and why would you? SQL is &lt;em&gt;awesome&lt;/em&gt;!), then you&amp;rsquo;ll feel right at home using the &lt;code&gt;JdbcTemplate&lt;/code&gt; and the various commands classes in the JDBC module. If not, Spring continues to meet you where you today with rich integrations for JDBC-centric data access technologies like JOOQ, Hibernate, JPA, MyBatis, Spring Data JPA, Spring Data JDBC, and a slew of other options. &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Hypertrace Java Agent creator Pavol Loffay</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/28/a-bootiful-podcast-hypertrace-java-agent-creator-pavol-loffay" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-29:4349</id>
    <updated>2021-01-29T01:13:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this episode &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Hypertrace Java Agent creator &lt;a href="http://twitter.com/ploffay"&gt;Pavol Loffay (@ploffay)&lt;/a&gt; about telemetry, observability, and more. &lt;/p&gt;
&lt;iframe title="Hypertrace Java Agent creator Pavol Loffay" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/vm8cv-f8f4ea?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud 2020.0.1 (aka Ilford) Is Available</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/28/spring-cloud-2020-0-1-aka-ilford-is-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Spencer Gibb</name>
    </author>
    <id>tag:spring.io,2021-01-28:4348</id>
    <updated>2021-01-28T20:38:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the community, I am pleased to announce that Service Release 1 of the &lt;a href="https://cloud.spring.io"&gt;Spring Cloud 2020.0&lt;/a&gt; Release Train (2020.0.1) is available today. The release can be found in &lt;a href="https://repo1.maven.org/maven2/org/springframework/cloud/spring-cloud-dependencies/2020.0.1/"&gt;Maven Central&lt;/a&gt;. You can check out the 2020.0 &lt;a href="https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-2020.0-Release-Notes"&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#notable-changes-in-the-2020-0-0-release-train" class="anchor" name="notable-changes-in-the-2020-0-0-release-train"&gt;&lt;/a&gt;Notable Changes in the 2020.0.0 Release Train&lt;/h2&gt;
&lt;p&gt;This release was primarliy for bug fixes and dependency upgrades.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;this page&lt;/a&gt; for a list of Known Issues.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"&gt;wiki&lt;/a&gt; for a list of all breaking changes in this release train.&lt;/p&gt;
&lt;p&gt;See all of the included issues and pull requests at the &lt;a href="https://github.com/orgs/spring-cloud/projects/52"&gt;Github project&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-config" class="anchor" name="spring-cloud-config"&gt;&lt;/a&gt;Spring Cloud Config&lt;/h3&gt;
&lt;p&gt;All of the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;known issues&lt;/a&gt; have been fixed.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-consul" class="anchor" name="spring-cloud-consul"&gt;&lt;/a&gt;Spring Cloud Consul&lt;/h3&gt;
&lt;p&gt;A new &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;known issue&lt;/a&gt; have been found, where the &lt;code&gt;spring.config.import=consul:&lt;/code&gt; does not support retry.&lt;/p&gt;
&lt;p&gt;The issue with improper order of contexts in the Config module has been fixed.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-zookeeper" class="anchor" name="spring-cloud-zookeeper"&gt;&lt;/a&gt;Spring Cloud Zookeeper&lt;/h3&gt;
&lt;p&gt;The issue with improper order of contexts in the Config module has been fixed.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;The following modules were updated as part of 2020.0.0:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module &lt;/th&gt;
      &lt;th&gt;Version &lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Circuitbreaker &lt;/td&gt;
      &lt;td&gt;2.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Contract &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Kubernetes &lt;/td&gt;
      &lt;td&gt;2.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Commons &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Openfeign &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cloudfoundry &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Bus &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cli &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Zookeeper &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Sleuth &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Consul &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Starter Build &lt;/td&gt;
      &lt;td&gt;2020.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gateway &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Netflix &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Vault &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Config &lt;/td&gt;
      &lt;td&gt;3.0.2 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Task &lt;/td&gt;
      &lt;td&gt;2.3.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href="https://github.com/spring-cloud/"&gt;GitHub&lt;/a&gt;, on &lt;a href="https://gitter.im/spring-cloud/spring-cloud"&gt;Gitter&lt;/a&gt;, on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud"&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href="https://twitter.com/SpringCloud"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with Maven with a BOM (dependency management only):&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint xml"&gt;&amp;lt;dependencyManagement&amp;gt;&#xD;
    &amp;lt;dependencies&amp;gt;&#xD;
        &amp;lt;dependency&amp;gt;&#xD;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
            &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;version&amp;gt;2020.0.1&amp;lt;/version&amp;gt;&#xD;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
        &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;/dependencies&amp;gt;&#xD;
&amp;lt;/dependencyManagement&amp;gt;&#xD;
&amp;lt;dependencies&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    ...&#xD;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint groovy"&gt;buildscript {&#xD;
  dependencies {&#xD;
    classpath &amp;quot;io.spring.gradle:dependency-management-plugin:1.0.11.RELEASE&amp;quot;&#xD;
  }&#xD;
}&#xD;
&#xD;
apply plugin: &amp;quot;io.spring.dependency-management&amp;quot;&#xD;
&#xD;
dependencyManagement {&#xD;
  imports {&#xD;
    mavenBom &amp;#39;org.springframework.cloud:spring-cloud-dependencies:2020.0.1&amp;#39;&#xD;
  }&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-config&amp;#39;&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&amp;#39;&#xD;
  //...&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Batch on Kubernetes: Efficient batch processing at scale</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/27/spring-batch-on-kubernetes-efficient-batch-processing-at-scale" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Mahmoud Ben Hassine</name>
    </author>
    <id>tag:spring.io,2021-01-13:4332</id>
    <updated>2021-01-27T23:00:00Z</updated>
    <content type="html">&lt;h2&gt;&lt;a href="#introduction" class="anchor" name="introduction"&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Batch processing has been a challenging area of computer science since its inception in the early days of punch cards and magnetic tapes. Nowadays, the modern cloud computing era comes with a whole new set of challenges for how to develop and operate batch workload efficiently in a cloud environment. In this blog post, I introduce some of the challenges a batch developer or architect may face when designing and running batch applications at scale and show how Spring Batch, Spring Boot and Kubernetes can tremendously simplify this task.&lt;/p&gt;&lt;h2&gt;&lt;a href="#challenges-of-designing-and-running-batch-workloads-in-the-cloud" class="anchor" name="challenges-of-designing-and-running-batch-workloads-in-the-cloud"&gt;&lt;/a&gt;Challenges of Designing and Running Batch Workloads in the Cloud&lt;/h2&gt;
&lt;p&gt;Designing cloud-native batch applications might seem easy compared to web applications, but this is not true. Batch developers face many challenges.&lt;/p&gt;&lt;h4&gt;&lt;a href="#1-fault-tolerance" class="anchor" name="1-fault-tolerance"&gt;&lt;/a&gt;1. Fault Tolerance&lt;/h4&gt;
&lt;p&gt;Batch processes typically interact with other services (such as databases, messages brokers, web services, and others) which are, by nature, flaky in cloud environments. Moreover, even the nodes on which those processes are run can die at any time and be replaced with healthy nodes. Cloud native batch applications should be designed in a fault-tolerant way.&lt;/p&gt;&lt;h4&gt;&lt;a href="#2-robustness" class="anchor" name="2-robustness"&gt;&lt;/a&gt;2. Robustness&lt;/h4&gt;
&lt;p&gt;It is not uncommon that the human error of running a batch job twice has some big financial consequences (such as what happened to &lt;a href="https://www.deseret.com/2000/8/29/19526136/oops-walgreen-accidentally-bills-credit-card-customers-twice"&gt;Walgreens&lt;/a&gt;, &lt;a href="https://www.smh.com.au/national/anzs-45m-bank-bungle-20060519-gdnksi.html"&gt;ANZ Bank&lt;/a&gt;, and &lt;a href="https://www.computerweekly.com/news/2240042675/NatWest-in-double-debit-error"&gt;NatWest&lt;/a&gt;, to name a few). Moreover, some platforms, such as Kubernetes, have some known limitations about the eventuality of &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-job-limitations"&gt;running the same job twice&lt;/a&gt;. A cloud native batch application should be ready to deal with this kind of issues by design.&lt;/p&gt;&lt;h4&gt;&lt;a href="#3-cost-efficiency" class="anchor" name="3-cost-efficiency"&gt;&lt;/a&gt;3. Cost Efficiency&lt;/h4&gt;
&lt;p&gt;Cloud infrastructures are billed by cpu/memory/bandwidth usage. In case of failure, It would be inefficient to not be able to restart a job from where it left off and &amp;ldquo;lose&amp;rdquo; the cpu/memory/bandwidth usage of the previous run (and hence be billed twice or more!).&lt;/p&gt;&lt;h4&gt;&lt;a href="#4-observability" class="anchor" name="4-observability"&gt;&lt;/a&gt;4. Observability&lt;/h4&gt;
&lt;p&gt;Any modern batch architecture should be able to know at any point in time some key metrics, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;What jobs are currently running?&lt;/li&gt;
  &lt;li&gt;Which jobs have failed, if any?&lt;/li&gt;
  &lt;li&gt;Other questions about how things are going.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Being able to have these KPIs at a glance on a dashboard is vital for efficient operations.&lt;/p&gt;&lt;h4&gt;&lt;a href="#5-scalability" class="anchor" name="5-scalability"&gt;&lt;/a&gt;5. Scalability&lt;/h4&gt;
&lt;p&gt;We are dealing with an unprecedented amounts of data, which is impossible to handle on a single machine any more. Correctly processing large volumes of distributed data is probably the most challenging point. Cloud-native batch applications should be scalable by design.&lt;/p&gt;
&lt;p&gt;All these aspects should be taken into consideration when designing and developing cloud-native batch applications. This is a considerable amount of work on the developer&amp;rsquo;s side. Spring Batch takes care of most of these issues. I explain the details in the next section.&lt;/p&gt;&lt;h2&gt;&lt;a href="#how-does-spring-batch-make-a-batch-developer-rsquo-s-life-easier" class="anchor" name="how-does-spring-batch-make-a-batch-developer-rsquo-s-life-easier"&gt;&lt;/a&gt;How does Spring Batch Make a Batch Developer&amp;rsquo;s Life easier?&lt;/h2&gt;
&lt;p&gt;Spring Batch is the de facto batch processing framework on the JVM. Entire books have been written on the rich feature set provided by Spring Batch, but I would like to highlight the most relevant features that address the previously mentioned challenges in the context of cloud-native development:&lt;/p&gt;&lt;h4&gt;&lt;a href="#1-fault-tolerance" class="anchor" name="1-fault-tolerance"&gt;&lt;/a&gt;1. Fault Tolerance&lt;/h4&gt;
&lt;p&gt;Spring Batch provides fault-tolerance feature, such as transaction management and skip and retry mechanisms, which are useful when batch jobs interact with flaky services in a cloud environment.&lt;/p&gt;&lt;h4&gt;&lt;a href="#2-robustness" class="anchor" name="2-robustness"&gt;&lt;/a&gt;2. Robustness&lt;/h4&gt;
&lt;p&gt;Spring Batch uses a centralized transactional job repository, which prevents duplicate job executions. By design, human errors and platform limitations that may lead to running the same job twice are impossible.&lt;/p&gt;&lt;h4&gt;&lt;a href="#3-cost-efficiency" class="anchor" name="3-cost-efficiency"&gt;&lt;/a&gt;3. Cost Efficiency&lt;/h4&gt;
&lt;p&gt;Spring Batch jobs maintain their state in an external database, which makes it possible to restart failed jobs where they left off. This is cost effective, compared to other solutions that would redo the work from the beginning and, hence, would be billed twice or more!&lt;/p&gt;&lt;h4&gt;&lt;a href="#4-observability" class="anchor" name="4-observability"&gt;&lt;/a&gt;4. Observability&lt;/h4&gt;
&lt;p&gt;Spring Batch provides integration with &lt;a href="https://micrometer.io"&gt;Micrometer&lt;/a&gt;, which is key in terms of observability. A Spring Batch-based batch infrastructure provides key metrics, such as the currently active jobs, read/write rates, failed jobs, and others. It can even be extended with custom metrics.&lt;/p&gt;&lt;h4&gt;&lt;a href="#5-scalability" class="anchor" name="5-scalability"&gt;&lt;/a&gt;5. Scalability&lt;/h4&gt;
&lt;p&gt;As already mentioned, Spring Batch jobs maintain their state in an external database. As a result, they are stateless processes from the &lt;a href="https://12factor.net"&gt;12 factors&lt;/a&gt; methodology point of view. This stateless nature makes them suitable to be containerized and executed in cloud environments in a scalable way. Moreover, Spring Batch provides several vertical and horizontal scaling techniques, such as multi-threaded steps and remote partitioning/chunking of data, to scale batch jobs in an efficient way.&lt;/p&gt;
&lt;p&gt;Spring Batch provides other features, but the ones mentioned above are very helpful when designing and developing cloud-native batch processes.&lt;/p&gt;&lt;h2&gt;&lt;a href="#how-does-kubernetes-make-the-batch-operator-rsquo-s-life-easier" class="anchor" name="how-does-kubernetes-make-the-batch-operator-rsquo-s-life-easier"&gt;&lt;/a&gt;How Does Kubernetes Make the Batch Operator&amp;rsquo;s Life Easier?&lt;/h2&gt;
&lt;p&gt;Kubernetes is the de facto container orchestration platform for the cloud. Operating a batch infrastructure at scale is far from being a trivial task, and Kubernetes really is a game changer in this space. Before the cloud era, in one of my previous jobs, I played the role of a batch operator and I had to manage a cluster of 4 machines dedicated to batch jobs. Here are some of the tasks I had to either do manually or find a way to automate with (bash!) scripts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ssh into each machine to check which jobs are currently running&lt;/li&gt;
  &lt;li&gt;ssh into each machine to collect the logs of failed jobs&lt;/li&gt;
  &lt;li&gt;ssh into each machine to upgrade job versions or update their configuration&lt;/li&gt;
  &lt;li&gt;ssh into each machine to kill hanging jobs and restart them&lt;/li&gt;
  &lt;li&gt;ssh into each machine to edit/update the crontab file for job scheduling&lt;/li&gt;
  &lt;li&gt;Many other similar tasks..&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these tasks are obviously inefficient and error prone, leaving four dedicated machines under-utilized due to poor resource management. If you are still doing such tasks in 2021 (either manually or via scripts), I believe it&amp;rsquo;s a good time to think about migrating your batch infrastructure to Kubernetes. The reason is that Kubernetes lets you do all these tasks with a &lt;strong&gt;single&lt;/strong&gt; command against the &lt;strong&gt;entire&lt;/strong&gt; cluster, and this is a &lt;strong&gt;huge&lt;/strong&gt; difference from an operational point of view. Moving to Kubernetes lets you:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ask the entire cluster about currently running jobs with a single command&lt;/li&gt;
  &lt;li&gt;Submit/schedule jobs without having to know on which node they will run&lt;/li&gt;
  &lt;li&gt;Update job definitions transparently&lt;/li&gt;
  &lt;li&gt;Automatically run jobs to completion (a Kubernetes job creates one or more pods and ensures that a specified number of them terminate successfully)&lt;/li&gt;
  &lt;li&gt;Optimize the usage of cluster&amp;rsquo;s resources (Kubernetes plays Tetris with the cluster&amp;rsquo;s machines) and hence optimize the bills!&lt;/li&gt;
  &lt;li&gt;Use many other interesting features&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;a href="#spring-batch-on-kubernetes-a-perfect-match-in-action" class="anchor" name="spring-batch-on-kubernetes-a-perfect-match-in-action"&gt;&lt;/a&gt;Spring Batch on Kubernetes: a perfect match, in action&lt;/h2&gt;
&lt;p&gt;In this section, I take the same job developed in Spring Batch&amp;rsquo;s &lt;a href="https://spring.io/guides/gs/batch-processing"&gt;getting started guide&lt;/a&gt; (which is a data ingestion job that loads some person data from a CSV file into a relational database table), containerize it, and deploy it on Kubernetes. If you want to go a step further by wrapping this job in a Spring Cloud Task and deploying it in a Spring Cloud Data Flow server, see &lt;a href="https://dataflow.spring.io/docs/batch-developer-guides/batch/data-flow-spring-batch"&gt;Deploy a Spring Batch application by Using Data Flow&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#1-set-up-a-database-server" class="anchor" name="1-set-up-a-database-server"&gt;&lt;/a&gt;1. Set up a Database Server&lt;/h3&gt;
&lt;p&gt;I use a MySQL database to store Spring Batch metadata. The database lives outside the Kubernetes cluster, and this is on purpose. The reason is to mimic a realistic migration path, where only stateless workloads are migrated to Kubernetes in a first step. For many companies, migrating databases to Kubernetes is not an option yet (and this is a reasonable decision). To start the database server, run the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ git clone git@github.com:benas/spring-batch-lab.git&#xD;
$ cd blog/spring-batch-kubernetes&#xD;
$ docker-compose -f src/docker/docker-compose.yml up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a MySQL container pre-populated with &lt;a href="https://github.com/spring-projects/spring-batch/blob/master/spring-batch-core/src/main/resources/org/springframework/batch/core/schema-mysql.sql"&gt;Spring Batch&amp;rsquo;s technical tables&lt;/a&gt; as well as the &lt;a href="https://github.com/spring-guides/gs-batch-processing/blob/master/initial/src/main/resources/schema-all.sql"&gt;business table, &lt;code&gt;PEOPLE&lt;/code&gt;&lt;/a&gt;. We can check this, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker exec -it mysql bash&#xD;
root@0a6596feb06d:/# mysql -u root test -p # the root password is &amp;quot;root&amp;quot;&#xD;
Enter password:&#xD;
Reading table information for completion of table and column names&#xD;
You can turn off this feature to get a quicker startup with -A&#xD;
&#xD;
Welcome to the MySQL monitor.  Commands end with ; or \g.&#xD;
Your MySQL connection id is 8&#xD;
Server version: 8.0.21 MySQL Community Server - GPL&#xD;
&#xD;
Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.&#xD;
&#xD;
Oracle is a registered trademark of Oracle Corporation and/or its&#xD;
affiliates. Other names may be trademarks of their respective&#xD;
owners.&#xD;
&#xD;
Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement.&#xD;
mysql&amp;gt; show tables;&#xD;
+------------------------------+&#xD;
| Tables_in_test               |&#xD;
+------------------------------+&#xD;
| BATCH_JOB_EXECUTION          |&#xD;
| BATCH_JOB_EXECUTION_CONTEXT  |&#xD;
| BATCH_JOB_EXECUTION_PARAMS   |&#xD;
| BATCH_JOB_EXECUTION_SEQ      |&#xD;
| BATCH_JOB_INSTANCE           |&#xD;
| BATCH_JOB_SEQ                |&#xD;
| BATCH_STEP_EXECUTION         |&#xD;
| BATCH_STEP_EXECUTION_CONTEXT |&#xD;
| BATCH_STEP_EXECUTION_SEQ     |&#xD;
| PEOPLE                       |&#xD;
+------------------------------+&#xD;
10 rows in set (0.01 sec)&#xD;
&#xD;
mysql&amp;gt; select * from PEOPLE;&#xD;
Empty set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a href="#2-create-a-bootiful-containerized-spring-batch-job" class="anchor" name="2-create-a-bootiful-containerized-spring-batch-job"&gt;&lt;/a&gt;2. Create a Bootiful, Containerized Spring Batch Job&lt;/h3&gt;
&lt;p&gt;Go to &lt;a href="https://start.spring.io"&gt;start.spring.io&lt;/a&gt; and generate a project with the following dependencies: Spring Batch and the MySQL driver. You can use this &lt;a href="https://start.spring.io/#!type=maven-project&amp;language=java&amp;platformVersion=2.4.1.RELEASE&amp;packaging=jar&amp;jvmVersion=1.8&amp;groupId=com.example&amp;artifactId=demo&amp;name=demo&amp;description=Demo%20project%20for%20Spring%20Boot&amp;packageName=com.example.demo&amp;dependencies=batch,mysql"&gt;link&lt;/a&gt; to create the project. After unzipping the project and loading it in your favorite IDE, you can change the main class, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;package com.example.demo;&#xD;
&#xD;
import java.net.MalformedURLException;&#xD;
&#xD;
import javax.sql.DataSource;&#xD;
&#xD;
import org.springframework.batch.core.Job;&#xD;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;&#xD;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;&#xD;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;&#xD;
import org.springframework.batch.core.configuration.annotation.StepScope;&#xD;
import org.springframework.batch.item.database.JdbcBatchItemWriter;&#xD;
import org.springframework.batch.item.database.builder.JdbcBatchItemWriterBuilder;&#xD;
import org.springframework.batch.item.file.FlatFileItemReader;&#xD;
import org.springframework.batch.item.file.builder.FlatFileItemReaderBuilder;&#xD;
import org.springframework.beans.factory.annotation.Value;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.core.io.UrlResource;&#xD;
&#xD;
@SpringBootApplication&#xD;
@EnableBatchProcessing&#xD;
public class DemoApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		System.exit(SpringApplication.exit(&#xD;
			SpringApplication.run(DemoApplication.class, args)));&#xD;
	}&#xD;
	&#xD;
	@Bean&#xD;
	@StepScope&#xD;
	public Resource resource(@Value(&amp;quot;#{jobParameters[&amp;#39;fileName&amp;#39;]}&amp;quot;) String fileName) throws MalformedURLException {&#xD;
		return new UrlResource(fileName);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public FlatFileItemReader&amp;lt;Person&amp;gt; itemReader(Resource resource)  {&#xD;
		return new FlatFileItemReaderBuilder&amp;lt;Person&amp;gt;()&#xD;
				.name(&amp;quot;personItemReader&amp;quot;)&#xD;
				.resource(resource)&#xD;
				.delimited()&#xD;
				.names(&amp;quot;firstName&amp;quot;, &amp;quot;lastName&amp;quot;)&#xD;
				.targetType(Person.class)&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public JdbcBatchItemWriter&amp;lt;Person&amp;gt; itemWriter(DataSource dataSource) {&#xD;
		return new JdbcBatchItemWriterBuilder&amp;lt;Person&amp;gt;()&#xD;
				.dataSource(dataSource)&#xD;
				.sql(&amp;quot;INSERT INTO PEOPLE (FIRST_NAME, LAST_NAME) VALUES (:firstName, :lastName)&amp;quot;)&#xD;
				.beanMapped()&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public Job job(JobBuilderFactory jobs, StepBuilderFactory steps,&#xD;
				   DataSource dataSource, Resource resource) {&#xD;
		return jobs.get(&amp;quot;job&amp;quot;)&#xD;
				.start(steps.get(&amp;quot;step&amp;quot;)&#xD;
						.&amp;lt;Person, Person&amp;gt;chunk(3)&#xD;
						.reader(itemReader(resource))&#xD;
						.writer(itemWriter(dataSource))&#xD;
						.build())&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	public static class Person {&#xD;
		private String firstName;&#xD;
		private String lastName;&#xD;
                // default constructor + getters/setters omitted for brevity&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;@EnableBatchProcessing&lt;/code&gt; annotation sets up all the infrastructure beans required by Spring Batch (job repository, job launcher, and others) as well as some utilities, such as &lt;code&gt;JobBuilderFactory&lt;/code&gt; and &lt;code&gt;StepBuilderFactory&lt;/code&gt; to facilitate the creation of steps and jobs. In the snippet above, I used those utilities to create a job with a single chunk-oriented step, defined as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An item reader that reads data from a &lt;code&gt;UrlResource&lt;/code&gt;. In some cloud environments, file systems are read-only or do not even exist, so the ability to stream data without downloading it is almost an essential requirement. Fortunately, Spring Batch has you covered! All file-based item readers (for flat files, XML files, and JSON files) work against the powerful Spring Framework &lt;code&gt;Resource&lt;/code&gt; abstraction, so any implementation of &lt;code&gt;Resource&lt;/code&gt; should work. In this example, I use a &lt;code&gt;UrlResource&lt;/code&gt; to read data directly from the &lt;a href="https://raw.githubusercontent.com/spring-guides/gs-batch-processing/master/initial/src/main/resources/sample-data.csv"&gt;remote URL of sample-data.csv&lt;/a&gt; at GitHub without downloading it. The file name is passed in as a job parameter.&lt;/li&gt;
  &lt;li&gt;An item writer that writes &lt;code&gt;Person&lt;/code&gt; items to the &lt;code&gt;PEOPLE&lt;/code&gt; table in MySQL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s it. Let&amp;rsquo;s package the job and create a docker image for it by using Spring Boot&amp;rsquo;s maven plugin:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ mvn package&#xD;
...&#xD;
$ mvn spring-boot:build-image -Dspring-boot.build-image.imageName=benas/bootiful-job&#xD;
[INFO] Scanning for projects...&#xD;
[INFO]&#xD;
…&#xD;
[INFO] --- spring-boot-maven-plugin:2.4.1:build-image (default-cli) @ demo ---&#xD;
[INFO] Building image &amp;#39;docker.io/benas/bootiful-job:latest&amp;#39;&#xD;
…&#xD;
[INFO] Successfully built image &amp;#39;docker.io/benas/bootiful-job:latest&amp;#39;&#xD;
[INFO]&#xD;
[INFO] ------------------------------------------------------------------------&#xD;
[INFO] BUILD SUCCESS
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The image should now be correctly built, but let&amp;rsquo;s check that:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker images&#xD;
REPOSITORY             TAG           IMAGE ID               CREATED             SIZE&#xD;
benas/bootiful-job     latest        52244b284f08    41 seconds ago   242MB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how Spring Boot created a Docker image without the need to create a Dockerfile! A complete blog post has been written about this awesome feature by the awesome Josh Long: &lt;a href="https://spring.io/blog/2021/01/04/ymnnalft-easy-docker-image-creation-with-the-spring-boot-maven-plugin-and-buildpacks"&gt;YMNNALFT: Easy Docker Image Creation with the Spring Boot Maven Plugin and Buildpacks&lt;/a&gt;. Now let&amp;rsquo;s run this job in a Docker container to check that everything is working as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker run \&#xD;
   -e SPRING_DATASOURCE_URL=jdbc:mysql://192.168.1.53:3306/test \&#xD;
   -e SPRING_DATASOURCE_USERNAME=root \&#xD;
   -e SPRING_DATASOURCE_PASSWORD=root \&#xD;
   -e SPRING_DATASOURCE_DRIVER-CLASS-NAME=com.mysql.cj.jdbc.Driver \&#xD;
   benas/bootiful-job \&#xD;
   fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see something like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;  .   ____          _            __ _ _&#xD;
 /\\ / ___&amp;#39;_ __ _ _(_)_ __  __ _ \ \ \ \&#xD;
( ( )\___ | &amp;#39;_ | &amp;#39;_| | &amp;#39;_ \/ _` | \ \ \ \&#xD;
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xD;
  &amp;#39;  |____| .__|_| |_|_| |_\__, | / / / /&#xD;
 =========|_|==============|___/=/_/_/_/&#xD;
 :: Spring Boot ::                (v2.4.1)&#xD;
&#xD;
2021-01-08 17:03:15.009  INFO 1 --- [           main] com.example.demo.DemoApplication         : Starting DemoApplication v0.0.1-SNAPSHOT using Java 1.8.0_275 on 876da4a1cfe0 with PID 1 (/workspace/BOOT-INF/classes started by cnb in /workspace)&#xD;
2021-01-08 17:03:15.012  INFO 1 --- [           main] com.example.demo.DemoApplication         : No active profile set, falling back to default profiles: default&#xD;
2021-01-08 17:03:15.899  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...&#xD;
2021-01-08 17:03:16.085  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.&#xD;
2021-01-08 17:03:16.139  INFO 1 --- [           main] o.s.b.c.r.s.JobRepositoryFactoryBean     : No database type set, using meta data indicating: MYSQL&#xD;
2021-01-08 17:03:16.292  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : No TaskExecutor has been set, defaulting to synchronous executor.&#xD;
2021-01-08 17:03:16.411  INFO 1 --- [           main] com.example.demo.DemoApplication         : Started DemoApplication in 1.754 seconds (JVM running for 2.383)&#xD;
2021-01-08 17:03:16.414  INFO 1 --- [           main] o.s.b.a.b.JobLauncherApplicationRunner   : Running default command line with: [fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv]&#xD;
2021-01-08 17:03:16.536  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] launched with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}]&#xD;
2021-01-08 17:03:16.596  INFO 1 --- [           main] o.s.batch.core.job.SimpleStepHandler     : Executing step: [step]&#xD;
2021-01-08 17:03:17.481  INFO 1 --- [           main] o.s.batch.core.step.AbstractStep         : Step: [step] executed in 884ms&#xD;
2021-01-08 17:03:17.501  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] completed with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}] and the following status: [COMPLETED] in 934ms&#xD;
2021-01-08 17:03:17.513  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...&#xD;
2021-01-08 17:03:17.534  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The job is now completed, and we can check that data has been successfully loaded in the database:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;mysql&amp;gt; select * from PEOPLE;&#xD;
+----+------------+-----------+&#xD;
| ID | FIRST_NAME | LAST_NAME |&#xD;
+----+------------+-----------+&#xD;
|  1 | Jill       | Doe       |&#xD;
|  2 | Joe        | Doe       |&#xD;
|  3 | Justin     | Doe       |&#xD;
|  4 | Jane       | Doe       |&#xD;
|  5 | John       | Doe       |&#xD;
+----+------------+-----------+&#xD;
5 rows in set (0.00 sec)&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s it! Now let&amp;rsquo;s deploy this job on Kubernetes. However, before moving on and deploying this job on Kubernetes, I want to show two things:&lt;/p&gt;&lt;h4&gt;&lt;a href="#preventing-duplicate-job-executions-of-the-same-job-instance" class="anchor" name="preventing-duplicate-job-executions-of-the-same-job-instance"&gt;&lt;/a&gt;Preventing Duplicate Job Executions of the Same Job Instance&lt;/h4&gt;
&lt;p&gt;If you want to see how Spring Batch prevents duplicate job executions, you can try to re-run the job with the same command. The application should fail to start with the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;2021-01-08 20:21:20.752 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xD;
&#xD;
java.lang.IllegalStateException: Failed to execute ApplicationRunner&#xD;
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:798) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:785) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:333) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1309) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1298) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at com.example.demo.DemoApplication.main(DemoApplication.java:30) [classes/:0.0.1-SNAPSHOT]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_275]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_275]&#xD;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_275]&#xD;
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_275]&#xD;
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:107) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) [workspace/:na]&#xD;
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) [workspace/:na]&#xD;
Caused by: org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException: A job instance already exists and is complete for parameters={fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}.  If you want to run this job again, change the parameters.&#xD;
…
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spring Batch does not let the same job instance be re-run after it has successfully completed. This is by design, to prevent duplicate job executions due to either a human error or a platform limitation, as explained in the previous section.&lt;/p&gt;&lt;h4&gt;&lt;a href="#preventing-concurrent-job-executions-of-the-same-job-instance" class="anchor" name="preventing-concurrent-job-executions-of-the-same-job-instance"&gt;&lt;/a&gt;Preventing Concurrent Job Executions of the Same Job Instance&lt;/h4&gt;
&lt;p&gt;In the same spirit, Spring Batch prevents concurrent executions of the same job instance. To test it, add an item processor that does a &lt;code&gt;Thread.sleep&lt;/code&gt; to slow down the processing and try to run a second job execution (in a separate terminal) while the first one is running. The second (concurrent) attempt fails with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;2021-01-08 20:59:04.201 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xD;
&#xD;
java.lang.IllegalStateException: Failed to execute ApplicationRunner&#xD;
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:798) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:785) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:333) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1309) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1298) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at com.example.demo.DemoApplication.main(DemoApplication.java:31) [classes/:0.0.1-SNAPSHOT]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_275]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_275]&#xD;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_275]&#xD;
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_275]&#xD;
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:107) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) [workspace/:na]&#xD;
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) [workspace/:na]&#xD;
Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobExecution: id=1, version=1, startTime=2021-01-08 20:58:46.434, endTime=null, lastUpdated=2021-01-08 20:58:46.435, status=STARTED, exitStatus=exitCode=UNKNOWN;exitDescription=, job=[JobInstance: id=1, version=0, Job=[job]], jobParameters=[{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}]&#xD;
…
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks to the centralized job repository, Spring Batch can detect currently running executions (based on the job status in the database) and prevent concurrent executions either on the same node or any other node of the cluster by throwing a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#3-deploy-the-job-on-kubernetes" class="anchor" name="3-deploy-the-job-on-kubernetes"&gt;&lt;/a&gt;3. Deploy the Job on Kubernetes&lt;/h3&gt;
&lt;p&gt;Setting up a Kubernetes cluster is beyond the scope of this post, so I assume you already have a Kubernetes cluster up and running and can interact with it by using &lt;code&gt;kubectl&lt;/code&gt;. In this post, I use the single-node local Kubernetes cluster provided by the Docker Desktop application.&lt;/p&gt;
&lt;p&gt;First, I create a service for the external database, as described in &amp;ldquo;Scenario 1: Database outside cluster with IP address&amp;rdquo; from &lt;a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-mapping-external-services"&gt;Kubernetes best practices: mapping external services&lt;/a&gt;. Here is the service definition: &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;kind: Service&#xD;
apiVersion: v1&#xD;
metadata:&#xD;
  name: mysql&#xD;
spec:&#xD;
    type: ClusterIP&#xD;
    ports:&#xD;
      - port: 3306&#xD;
        targetPort: 3306&#xD;
---&#xD;
kind: Endpoints&#xD;
apiVersion: v1&#xD;
metadata:&#xD;
  name: mysql&#xD;
subsets:&#xD;
  - addresses:&#xD;
      - ip: 192.168.1.53 # This is my local IP, you might need to change it if needed&#xD;
    ports:&#xD;
      - port: 3306&#xD;
---&#xD;
apiVersion: v1&#xD;
kind: Secret&#xD;
metadata:&#xD;
  name: db-secret&#xD;
type: Opaque&#xD;
data:&#xD;
  # base64 of &amp;quot;root&amp;quot; ($&amp;gt;echo -n &amp;quot;root&amp;quot; | base64)&#xD;
  db.username: cm9vdA==&#xD;
  db.password: cm9vdA==
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This service can be applied to Kubernetes, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ kubectl apply -f src/kubernetes/database-service.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, since we have already created a Docker image for our job, deploying it to Kubernetes is a matter of defining a &lt;code&gt;Job&lt;/code&gt; resource with the following manifest:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;apiVersion: batch/v1&#xD;
kind: Job&#xD;
metadata:&#xD;
  name: bootiful-job-$JOB_NAME&#xD;
spec:&#xD;
  template:&#xD;
    spec:&#xD;
      restartPolicy: OnFailure&#xD;
      containers:&#xD;
        - name: bootiful-job&#xD;
          image: benas/bootiful-job&#xD;
          imagePullPolicy: Never&#xD;
          args: [&amp;quot;fileName=$FILE_NAME&amp;quot;]&#xD;
          env:&#xD;
            - name: SPRING_DATASOURCE_DRIVER-CLASS-NAME&#xD;
              value: com.mysql.cj.jdbc.Driver&#xD;
            - name: SPRING_DATASOURCE_URL&#xD;
              value: jdbc:mysql://mysql/test&#xD;
            - name: SPRING_DATASOURCE_USERNAME&#xD;
              valueFrom:&#xD;
                secretKeyRef:&#xD;
                  name: db-secret&#xD;
                  key: db.username&#xD;
            - name: SPRING_DATASOURCE_PASSWORD&#xD;
              valueFrom:&#xD;
                secretKeyRef:&#xD;
                  name: db-secret&#xD;
                  key: db.password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This manifest follows the same approach as &lt;a href="https://kubernetes.io/docs/tasks/job/parallel-processing-expansion/"&gt;creating jobs based on a template&lt;/a&gt;, as suggested by Kubernetes docs. This job template serves as a base for creating a job for each input file to ingest. I have already ingested the &lt;code&gt;sample1.csv&lt;/code&gt; file, so I create a job for another remote file named &lt;a href="https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv"&gt;sample2.csv&lt;/a&gt; by using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ JOB_NAME=sample2 \&#xD;
  FILE_NAME=&amp;quot;https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv&amp;quot; \&#xD;
  envsubst &amp;lt; src/k8s/job.yaml | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command substitutes variables in the job template to create a job definition for the given file and then submits it to Kubernetes. Let&amp;rsquo;s check the job and pod resources in Kubernetes:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ kubectl get jobs&#xD;
NAME                  COMPLETIONS   DURATION   AGE&#xD;
bootiful-job-sample2   0/1           97s        97s&#xD;
&#xD;
$ kubectl get pods&#xD;
NAME                             READY   STATUS      RESTARTS   AGE&#xD;
bootiful-job-sample2-n8mlb   0/1     Completed   0          7s&#xD;
&#xD;
$ kubectl logs bootiful-job-sample2-n8mlb&#xD;
  .   ____          _            __ _ _&#xD;
 /\\ / ___&amp;#39;_ __ _ _(_)_ __  __ _ \ \ \ \&#xD;
( ( )\___ | &amp;#39;_ | &amp;#39;_| | &amp;#39;_ \/ _` | \ \ \ \&#xD;
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xD;
  &amp;#39;  |____| .__|_| |_|_| |_\__, | / / / /&#xD;
 =========|_|==============|___/=/_/_/_/&#xD;
 :: Spring Boot ::                (v2.4.1)&#xD;
&#xD;
2021-01-08 17:48:42.053  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : Starting BootifulJobApplication v0.1 using Java 1.8.0_275 on bootiful-job-person-n8mlb with PID 1 (/workspace/BOOT-INF/classes started by cnb in /workspace)&#xD;
2021-01-08 17:48:42.056  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : No active profile set, falling back to default profiles: default&#xD;
2021-01-08 17:48:43.028  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...&#xD;
2021-01-08 17:48:43.180  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.&#xD;
2021-01-08 17:48:43.231  INFO 1 --- [           main] o.s.b.c.r.s.JobRepositoryFactoryBean     : No database type set, using meta data indicating: MYSQL&#xD;
2021-01-08 17:48:43.394  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : No TaskExecutor has been set, defaulting to synchronous executor.&#xD;
2021-01-08 17:48:43.541  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : Started BootifulJobApplication in 1.877 seconds (JVM running for 2.338)&#xD;
2021-01-08 17:48:43.544  INFO 1 --- [           main] o.s.b.a.b.JobLauncherApplicationRunner   : Running default command line with: [fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv]&#xD;
2021-01-08 17:48:43.677  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] launched with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv}]&#xD;
2021-01-08 17:48:43.758  INFO 1 --- [           main] o.s.batch.core.job.SimpleStepHandler     : Executing step: [step]&#xD;
2021-01-08 17:48:44.632  INFO 1 --- [           main] o.s.batch.core.step.AbstractStep         : Step: [step] executed in 873ms&#xD;
2021-01-08 17:48:44.653  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] completed with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv}] and the following status: [COMPLETED] in 922ms&#xD;
2021-01-08 17:48:44.662  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...&#xD;
2021-01-08 17:48:44.693  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then check the newly added persons in the &lt;code&gt;PEOPLE&lt;/code&gt; table:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;mysql&amp;gt; select * from PEOPLE;&#xD;
+----+------------+-----------+&#xD;
| ID | FIRST_NAME | LAST_NAME |&#xD;
+----+------------+-----------+&#xD;
|  1 | Jill       | Doe       |&#xD;
|  2 | Joe        | Doe       |&#xD;
|  3 | Justin     | Doe       |&#xD;
|  4 | Jane       | Doe       |&#xD;
|  5 | John       | Doe       |&#xD;
|  6 | David      | Doe       |&#xD;
|  7 | Damien     | Doe       |&#xD;
|  8 | Danny      | Doe       |&#xD;
|  9 | Dorothy    | Doe       |&#xD;
|  10 | Daniel    | Doe       |&#xD;
&#xD;
+----+------------+-----------+&#xD;
10 rows in set (0.00 sec)&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s it, our job is successfully running in Kubernetes!&lt;/p&gt;&lt;h2&gt;&lt;a href="#tips-and-tricks" class="anchor" name="tips-and-tricks"&gt;&lt;/a&gt;Tips and Tricks&lt;/h2&gt;
&lt;p&gt;Before concluding this post, I wanted to share some tips and tricks that are worth considering when migrating Spring Batch jobs to the cloud on Kubernetes.&lt;/p&gt;&lt;h3&gt;&lt;a href="#1-job-packaging-and-deployment" class="anchor" name="1-job-packaging-and-deployment"&gt;&lt;/a&gt;1. Job Packaging and Deployment&lt;/h3&gt;
&lt;p&gt;Running more than one Spring Batch job in a single container or pod is not a good idea. This does not follow the cloud-native development best practices and the Unix philosophy in general. Running a job per container or pod has the following advantages:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Separate logs&lt;/li&gt;
  &lt;li&gt;Independent life cycles (bugs, features, deployments, etc)&lt;/li&gt;
  &lt;li&gt;Separate parameters and exit codes&lt;/li&gt;
  &lt;li&gt;Restartability (in case of failure, only restart the failed job)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#2-choosing-the-right-spring-batch-job-parameters" class="anchor" name="2-choosing-the-right-spring-batch-job-parameters"&gt;&lt;/a&gt;2. Choosing the Right Spring Batch Job Parameters&lt;/h3&gt;
&lt;p&gt;A successful Spring Batch job instance cannot be restarted. In the same way, a successful Kubernetes job cannot be restarted. This makes designing a Kubernetes job per Spring Batch job instance a perfect match! As a consequence, correctly choosing the identifying job parameters in Spring Batch becomes a crucial task, as doing so determines the identity of job instances and consequently the design of Kubernetes jobs (See point 3). Two important aspects of the framework are affected by this choice:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Job identification: Spring Batch prevents duplicate and concurrent job executions based on the identity of the job instance.&lt;/li&gt;
  &lt;li&gt;Failure scenario: Spring Batch relies on the job instance&amp;rsquo;s identity to start a new job execution where the previous one left off.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Batch processing is about processing &lt;strong&gt;fixed, immutable&lt;/strong&gt; data sets. If the input data is not fixed, then a stream-processing tool is more appropriate. Identifying job parameters in Spring Batch should represent a &lt;strong&gt;uniquely identifiable immutable&lt;/strong&gt; data set. A good hint to correctly choose a set of identifying job parameters is calculating their hash (or more precisely the hash of the data they represent) and making sure that that hash is stable. Here are some examples:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Job parameters &lt;/th&gt;
      &lt;th align="center"&gt;Good/Bad &lt;/th&gt;
      &lt;th align="right"&gt;Comments &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;fileName=log.txt &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;An ever growing log file is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fileName=transactions-2020-08-20.csv &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;As long as the file content is fixed &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;folderName=/in/data &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;A folder with a variable content is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;folderName=/in/data/2020/12/20 &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;A folder with the files of all orders received on a given day &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jmsQueueName=events &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;Items are removed from the queue so this is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;orderDate=2020-08-20 &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;If used, for example, in a database select query on D+1 &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unfortunately, many people fail at designing good identifying job parameters and end up adding a timestamp or a random number as an additional identifying job parameter acting as job instance discriminator. Using an ever growing “run.id” parameter is a symptom of such a failure.&lt;/p&gt;&lt;h3&gt;&lt;a href="#3-choosing-the-right-kubernetes-job-deployment-pattern" class="anchor" name="3-choosing-the-right-kubernetes-job-deployment-pattern"&gt;&lt;/a&gt;3. Choosing the Right Kubernetes Job Deployment Pattern&lt;/h3&gt;
&lt;p&gt;The Kubernetes&amp;rsquo; documentation provides a whole section called &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/#job-patterns"&gt;Job patterns&lt;/a&gt;, which describes how to choose the right job deployment pattern. In this post, I followed the &lt;a href="https://kubernetes.io/docs/tasks/job/parallel-processing-expansion/"&gt;Parallel processing using expansions&lt;/a&gt; approach to create a job per file from a template. While this approach allows for processing multiple files in parallel, it can put a pressure on Kubernetes when there are many files to ingest, as this would result in many Kubernetes job objects being created. If all your files have a similar structure and you want to create a single job to ingest them in one shot, you can use the &lt;code&gt;MultiResourceItemReader&lt;/code&gt; provided by Spring Batch and create a single Kubernetes job. Another option is to use a single job with a partitioned step where each worker step handles a file (this can be achieved by using the built-in &lt;code&gt;MultiResourcePartitioner&lt;/code&gt;).&lt;/p&gt;&lt;h3&gt;&lt;a href="#4-graceful-abrupt-shutdown-implication" class="anchor" name="4-graceful-abrupt-shutdown-implication"&gt;&lt;/a&gt;4. Graceful/Abrupt Shutdown Implication&lt;/h3&gt;
&lt;p&gt;When a Spring Batch job execution fails, you can restart it if the job instance is restartable. You can automate this, as long as the job execution is shut down gracefully, since this gives Spring Batch a chance to correctly set the job execution&amp;rsquo;s status to &lt;code&gt;FAILED&lt;/code&gt; and set its &lt;code&gt;END_TIME&lt;/code&gt; to a non-null value. However, if the job execution fails abruptly, the job execution&amp;rsquo;s status is still be set to &lt;code&gt;STARTED&lt;/code&gt; and its &lt;code&gt;END_TIME&lt;/code&gt; is &lt;code&gt;null&lt;/code&gt;. When you try to restart such a job execution, Spring Batch will think (since it only looks at the database status) that a job execution is currently running for this instance and fails with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. In such cases, the metadata tables should be updated to allow the restart of such a failed execution &amp;ndash; something like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;&amp;gt; update BATCH_JOB_EXECUTION set status = &amp;#39;FAILED&amp;#39;, END_TIME = &amp;#39;2020-01-15 10:10:28.235&amp;#39; where job_execution_id = X;&#xD;
&amp;gt; update BATCH_STEP_EXECUTION set status = &amp;#39;FAILED&amp;#39; where job_execution_id = X and step_name=&amp;#39;failed step name&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Graceful/Abrupt shutdown of Spring Batch jobs is directly related to Kubernetes jobs restart policy. For example, with &lt;code&gt;restartPolicy=OnFailure&lt;/code&gt;, when a pod fails abruptly and the job controller creates a new pod immediately after, you cannot update the database in a timely manner and the new Spring Batch job execution fails with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. The same happens with the third pod and so on, until the pod reaches the &lt;code&gt;CrashLoopBackOff&lt;/code&gt; state and gets deleted once the &lt;code&gt;backoffLimit&lt;/code&gt; is exceeded.&lt;/p&gt;
&lt;p&gt;Now, if you follow the best practice of running your Spring Boot Batch application with &lt;code&gt;System.exit(SpringApplication.exit(SpringApplication.run(MyBatchApplication.class, args)));&lt;/code&gt; as shown in the snippet above, Spring Boot (and, in turn, Spring Batch) can correctly handle &lt;code&gt;SIGTERM&lt;/code&gt; signals and gracefully shutdown your application when Kubernetes starts the &lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination"&gt;pod termination process&lt;/a&gt;. With this in place, when pods are gracefully shutdown, the Spring Batch job instance can automatically restart until completion. Unfortunately, graceful shutdown of Kubernetes pods is not guaranteed, and you should take this into consideration when you set the restart policy and the &lt;code&gt;backoffLimit&lt;/code&gt; values, to ensure you have enough time to update the job repository as needed for failed jobs.&lt;/p&gt;
&lt;p&gt;It should be noted that the &lt;code&gt;shell&lt;/code&gt; form of docker&amp;rsquo;s &lt;code&gt;ENTRYPOINT&lt;/code&gt; &lt;a href="https://docs.docker.com/engine/reference/builder/#entrypoint"&gt;does not send Unix signals to the sub-process running in the container&lt;/a&gt;. So in order to correctly intercept Unix signals by the Spring Batch job running in a container, the &lt;code&gt;ENTRYPOINT&lt;/code&gt; form should be &lt;code&gt;exec&lt;/code&gt;. This is also directly related to Kubernetes&amp;rsquo; pod termination process mentioned above. More details about this matter can be found in the &lt;a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace"&gt;Kubernetes best practices: terminating with grace&lt;/a&gt; blog post.&lt;/p&gt;&lt;h3&gt;&lt;a href="#5-choosing-the-right-kubernetes-job-concurrency-policy" class="anchor" name="5-choosing-the-right-kubernetes-job-concurrency-policy"&gt;&lt;/a&gt;5. Choosing the Right Kubernetes Job Concurrency Policy&lt;/h3&gt;
&lt;p&gt;As I pointed out earlier, Spring Batch prevents concurrent job executions of the same job instance. So, if you follow the &amp;ldquo;Kubernetes job per Spring Batch job instance&amp;rdquo; deployment pattern, setting the job&amp;rsquo;s &lt;code&gt;spec.parallelism&lt;/code&gt; to a value higher than 1 does not make sense, as this starts two pods in parallel and one of them will certainly fail with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. However, setting a &lt;code&gt;spec.parallelism&lt;/code&gt; to a value higher than 1 makes perfect sense for a partitioned job. In this case, partitions can be executed in parallel pods. Correctly choosing the concurrency policy is tightly related to which job pattern is chosen (As explained in point 3).&lt;/p&gt;&lt;h3&gt;&lt;a href="#6-job-metadata-housekeeping" class="anchor" name="6-job-metadata-housekeeping"&gt;&lt;/a&gt;6. Job Metadata Housekeeping&lt;/h3&gt;
&lt;p&gt;Deleting a Kubernetes job deletes its corresponding pods. Kubernetes provides a way to automatically clean up completed jobs by using the &lt;code&gt;ttlSecondsAfterFinished&lt;/code&gt; parameter. However, there is no equivalent to this in Spring Batch: You should clean up the job repository manually. You should take this into consideration for any serious production batch infrastructure, as job instances and executions can grow very quickly, depending on the frequency and number of deployed jobs. I see a good opportunity here to create a Kubernetes Custom Resource Definition that deletes Spring Batch&amp;rsquo;s metadata when the corresponding Kubernetes job is deleted.&lt;/p&gt;&lt;h2&gt;&lt;a href="#conclusion" class="anchor" name="conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this post has shed some light on the challenges of designing, developing, and running batch applications in the cloud and how Spring Batch, Spring Boot and Kubernetes can tremendously simplify this task. This post showed how to go from &lt;a href="https://start.spring.io"&gt;start.spring.io&lt;/a&gt; to Kubernetes in three simple steps, thanks to the productivity of the Spring ecosystem, but this is only scratching the surface of the matter. This post is the first part of a blog series in which I will cover other aspects of running Spring Batch jobs on Kubernetes. In the next posts, I will tackle job observability with &lt;a href="https://micrometer.io"&gt;Micrometer&lt;/a&gt; and &lt;a href="https://tanzu.vmware.com/observability"&gt;Wavefront&lt;/a&gt; and then how to scale Spring Batch jobs on Kubernetes. Stay tuned!&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT:  The Spring *Utils Classes</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/27/ymnnalft-the-spring-utils-classes" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4323</id>
    <updated>2021-01-27T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve all been there. There&amp;rsquo;s some everyday string-manipulation routine you want, so you extract it out into a separate abstract class and expose it as a &lt;code&gt;static&lt;/code&gt; method. Then, there&amp;rsquo;s some factory method for building a &lt;code&gt;java.util.Collection&amp;lt;T&amp;gt;&lt;/code&gt;, so you extract it out into a separate class and expose it as a &lt;code&gt;static&lt;/code&gt; method. And eventually, you&amp;rsquo;ve got a whole collection of these things scoured about your codebase, and there&amp;rsquo;s little to no cohesion across them. After all, there&amp;rsquo;s just not that much to it, right? These are, essentially, only global functions, not really methods on stateful objects, &lt;em&gt;per se&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not to say that building your own static methods is inherently wrong, as long as you approach them with some conventions. We typically use abstract classes with static methods, for example.&lt;/p&gt;
&lt;p&gt;It all starts off so innocuously. Of course, it does. You know the cycle. First, a few methods in a solitary class stuck in a jar in a company-wide artifact repository. Then there are classes, plural. Now &lt;em&gt;packages&lt;/em&gt; have entered the picture. Packages are trouble! You&amp;rsquo;ll start to realize that some thought had better go into an organization, or things will quickly get out of hand. You start accepting pull requests. At some point, there are breaking changes, and developers with pitchforks line up outside your door. You wonder why everyone keeps eating slashing your tires at work. It&amp;rsquo;s too much! So you get the company to open-source your nascent module. It&amp;rsquo;s the &lt;em&gt;world&lt;/em&gt;&amp;rsquo;s problem now! Like Tamagotchis and reality TV, there can be no end. And that wide world? Well, that wide world &lt;em&gt;loves&lt;/em&gt; breaking changes in point-releases, and they will &lt;em&gt;love you&lt;/em&gt; for them! &lt;/p&gt;
&lt;p&gt;Maybe.&lt;/p&gt;
&lt;p&gt;There is another way. &lt;/p&gt;
&lt;p&gt;There are many third-party utility libraries of varying quality out there: GS Collections, Apache Commons, Guava, etc. There is no shortage of options here. Did you know Spring offers several utility classes in the frameworks themselves, potentially sparing you a dependency? I&amp;rsquo;m not saying that they&amp;rsquo;ll do everything you might get from the distinguished competition, but you might be surprised! This example will look at a handful of these utility classes, but there are many others on the classpath. You can typically find them by going into your IDE and searching for &lt;code&gt;*Utils&lt;/code&gt; in your class search or &lt;code&gt;*Utils.java&lt;/code&gt; in your file search. Let&amp;rsquo;s take a look at some of them.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Many of these are included by default in every Spring Boot project through the following transitive (or default) dependency on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.utils;&#xD;
&#xD;
import lombok.AllArgsConstructor;&#xD;
import lombok.Data;&#xD;
import lombok.extern.log4j.Log4j2;&#xD;
import org.springframework.aop.support.AopUtils;&#xD;
import org.springframework.beans.BeanUtils;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.ResolvableType;&#xD;
import org.springframework.core.io.ClassPathResource;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.jmx.support.JmxUtils;&#xD;
import org.springframework.stereotype.Component;&#xD;
import org.springframework.util.*;&#xD;
&#xD;
import javax.annotation.PostConstruct;&#xD;
import java.beans.PropertyDescriptor;&#xD;
import java.io.InputStreamReader;&#xD;
import java.io.Reader;&#xD;
import java.io.Serializable;&#xD;
import java.lang.reflect.Constructor;&#xD;
import java.lang.reflect.Field;&#xD;
import java.util.*;&#xD;
&#xD;
@Log4j2&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	@Data&#xD;
	@AllArgsConstructor&#xD;
	@Component&#xD;
	public static class DemoClass {&#xD;
&#xD;
		@PostConstruct&#xD;
		public void begin() {&#xD;
			log.info(&amp;quot;begin()&amp;quot;);&#xD;
		}&#xD;
&#xD;
		private final List&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();&#xD;
&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(DemoClass demo) {&#xD;
		return event -&amp;gt; {&#xD;
&#xD;
			Assert.notNull(demo.getList(), &amp;quot;the list can&amp;#39;t be null&amp;quot;);&#xD;
&#xD;
			beansUtils(demo);&#xD;
			classUtils();&#xD;
			systemPropertyUtils();&#xD;
			fileCopyUtils();&#xD;
			aop(demo);&#xD;
			reflection();&#xD;
			ensure();&#xD;
			collections();&#xD;
			serialize();&#xD;
&#xD;
		};&#xD;
	}&#xD;
&#xD;
	private void ensure() {&#xD;
		int counter = 2;&#xD;
		Assert.state(counter == 2, () -&amp;gt; &amp;quot;the counter should be 2 or more. Was &amp;quot; + counter);&#xD;
		Assert.hasText(&amp;quot;Hello, world!&amp;quot;, () -&amp;gt; &amp;quot;this string should be a non-null, non-empty String&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void reflection() {&#xD;
&#xD;
		ReflectionUtils.doWithFields(DemoClass.class, field -&amp;gt; log.info(&amp;quot;field = &amp;quot; + field.toString()));&#xD;
		ReflectionUtils.doWithMethods(DemoClass.class, method -&amp;gt; log.info(&amp;quot;method = &amp;quot; + method.toString()));&#xD;
&#xD;
		Field list = ReflectionUtils.findField(DemoClass.class, &amp;quot;list&amp;quot;);&#xD;
		log.info(Objects.requireNonNull(list).toString());&#xD;
&#xD;
		ResolvableType rt = ResolvableType.forField(list);&#xD;
		log.info(rt.toString());&#xD;
	}&#xD;
&#xD;
	private void aop(DemoClass demoClass) {&#xD;
		Class&amp;lt;?&amp;gt; targetClass = AopUtils.getTargetClass(demoClass);&#xD;
		log.info(&amp;quot;Class&amp;lt;?&amp;gt; is &amp;quot; + targetClass);&#xD;
		log.info(&amp;quot;is AOP proxy? &amp;quot; + AopUtils.isAopProxy(demoClass));&#xD;
		log.info(&amp;quot;is CGlib proxy? &amp;quot; + AopUtils.isCglibProxy(demoClass));&#xD;
	}&#xD;
&#xD;
	private void collections() {&#xD;
		Collection&amp;lt;String&amp;gt; names = Arrays.asList(&amp;quot;Tammie&amp;quot;, &amp;quot;Kimly&amp;quot;, &amp;quot;Josh&amp;quot;);&#xD;
		boolean contains = CollectionUtils.containsAny(names, Arrays.asList(&amp;quot;Josh&amp;quot;));&#xD;
		Assert.state(contains, () -&amp;gt; &amp;quot;one or more of the names in &amp;quot; + names.toString() + &amp;quot; should be present&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void serialize() {&#xD;
		Customer in = new Customer(593232329, &amp;quot;Josh&amp;quot;);&#xD;
		byte[] bytes = SerializationUtils.serialize(in);&#xD;
		Customer out = (Customer) SerializationUtils.deserialize(bytes);&#xD;
		Assert.state(out.getId() == in.getId() &amp;amp;&amp;amp; out.getName().equals(in.getName()),&#xD;
				() -&amp;gt; &amp;quot;the &amp;quot; + Customer.class.getName() + &amp;quot; did not serialize correctlyy&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void fileCopyUtils() {&#xD;
		Resource cpr = new ClassPathResource(&amp;quot;/application.properties&amp;quot;);&#xD;
		try (Reader r = new InputStreamReader(cpr.getInputStream())) {&#xD;
			String contents = FileCopyUtils.copyToString(r);&#xD;
			log.info(&amp;quot;application.properties contents: &amp;quot; + contents);&#xD;
		}&#xD;
		catch (Exception e) {&#xD;
			throw new RuntimeException(e);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	private void systemPropertyUtils() {&#xD;
		String resolvedText = SystemPropertyUtils.resolvePlaceholders(&amp;quot;my home directory is ${user.home}&amp;quot;);&#xD;
		log.info(&amp;quot;resolved text: &amp;quot; + resolvedText);&#xD;
	}&#xD;
&#xD;
	private void classUtils() {&#xD;
		Constructor&amp;lt;DemoClass&amp;gt; demoClassConstructor = ClassUtils.getConstructorIfAvailable(DemoClass.class);&#xD;
		log.info(&amp;quot;demoClassConstructor: &amp;quot; + demoClassConstructor);&#xD;
		try {&#xD;
			DemoClass demoClass = demoClassConstructor.newInstance();&#xD;
			log.info(&amp;quot;newInstance&amp;#39;d demoClass: &amp;quot; + demoClass);&#xD;
		}&#xD;
		catch (Exception e) {&#xD;
			throw new RuntimeException(e);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	private void beansUtils(DemoClass demo) {&#xD;
		PropertyDescriptor[] descriptors = BeanUtils.getPropertyDescriptors(demo.getClass());&#xD;
		for (PropertyDescriptor pd : descriptors) {&#xD;
			log.info(&amp;quot;pd: &amp;quot; + pd.getName());&#xD;
		}&#xD;
	}&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
}&#xD;
&#xD;
@Data&#xD;
class Customer implements Serializable {&#xD;
&#xD;
	static final long serialVersionUID = 1L;&#xD;
&#xD;
	private int id;&#xD;
&#xD;
	private String name;&#xD;
&#xD;
	public Customer(int id, String name) {&#xD;
		this.id = id;&#xD;
		this.name = name;&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example introduces a &lt;em&gt;smörgåsbord&lt;/em&gt; of various &lt;code&gt;Utils&lt;/code&gt; class implementations in the Spring ecosystem. It looks at &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;BeanUtils&lt;/code&gt; - useful functions for dealing with JavaBeans&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ClassUtils&lt;/code&gt; - useful functions for asking questions reflectively about types&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;SystemPropertyUtils&lt;/code&gt; - useful functions for dealing with &lt;code&gt;System&lt;/code&gt; properties&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;FileCopyUtils&lt;/code&gt; - useful functions for copying &lt;code&gt;InputStream&lt;/code&gt; and &lt;code&gt;OutputStream&lt;/code&gt; implementations&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;AopUtils&lt;/code&gt; - useful functions for dealing with Spring&amp;rsquo;s AOP proxies&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ReflectionUtils&lt;/code&gt; - useful functions for dealing with reflection, broadly&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Assert&lt;/code&gt; - useful functions to help with design-by-contract-style assertions&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;CollectionUtils&lt;/code&gt; - useful functions for working various Java &lt;code&gt;java.util.Collection&lt;/code&gt; types&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;SerializeUtils&lt;/code&gt; - useful functions for working with Java serialization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There&amp;rsquo;s a &lt;em&gt;ton&lt;/em&gt; of exciting stuff, and this dense example doesn&amp;rsquo;t even begin to scratch the surface! &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - January 26th, 2021</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/26/this-week-in-spring-january-26th-2021" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-26:4347</id>
    <updated>2021-01-26T21:50:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! As I type this I&amp;rsquo;m sitting on the amazing Tanzu Tuesday&amp;rsquo;s stream as a (guest) cohost &lt;a href="http://twitter.com/tiffanyfayj"&gt;with Tiffany Jernigan (@tiffanyfayj)&lt;/a&gt; learning about tips and tricks for working with Spring Boot and Kubernetes from the &lt;a href="http://twitter.com/olliehughes82"&gt;Spring team&amp;rsquo;s Oliver Hughes (@olliehughes82)&lt;/a&gt;. If you missed it, then it - and all sorts of other content - is available for replays on our &lt;a href="http://twitch.tv/vmwaretanzu"&gt;Tanzu Twitch.tv channel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now then, we&amp;rsquo;ve got a ton of good stuff to get to so let&amp;rsquo;s gooo&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tomorrow, I&amp;rsquo;ll be streaming with Reactor team member and &lt;a href="https://tanzu.vmware.com/developer/tv/code/0018/"&gt;RSocket committer Oleh Dokuka on Twitch.tv/vmwaretanzu&lt;/a&gt; - don&amp;rsquo;t miss it!&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/springcloud/status/1352347656178302997"&gt;Mark your calendars! Call for Papers and registration for SpringOne 2021 open on Feb. 16. Sign up for updates&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/a-bootiful-podcast-spring-tools-lead-martin-lippert-on-sustainable-software"&gt;A Bootiful Podcast - Spring Tools lead Martin Lippert on sustainable software&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/bootiful-application-monitoring-with-azure-spring-cloud"&gt;Bootiful Application Monitoring with Azure Spring Cloud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1352321956138217474"&gt;You can monitor Azure Spring Cloud Spring Boot apps and dependencies without any effort! Brought to you jointly by Microsoft and VMware &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/20/ymnnalft-dimensional-metrics-accumulation-with-micrometer"&gt;YMNNALFT: Dimensional Metrics Accumulation with Micrometer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=j6Y-K0J7HD4&amp;feature=share"&gt;Building a Spring Boot and Spring MVC web application&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://developer.okta.com/blog/2021/01/20/reactive-java-microservices"&gt;The Okta blog has a nice post on reactive Java microservices &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/trankchung/kubeswitch/"&gt;Kubeswitch v0.2.0 - Kubernetes context and namespace switching&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.javavogue.com/2019/02/how-to-create-a-rest-api-with-spring-boot/"&gt;How to create a REST API with Spring Boot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://jishuin.proginn.com/p/763bfbd382bf"&gt;An interesting post on RSocket (?? REST ?????)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/spring-boot-2-5-0-m1-available-now"&gt;Spring Boot 2.5.0-M1 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/rorypreddy/status/1353338898219479044?s=12"&gt;The Azure Spring Cloud VSCode extension is out!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;I really enjoyed this discussion - &lt;a href="https://www.reddit.com/r/kubernetes/comments/l2l9jf/top_considerations_when_evaluating_an_ingress/"&gt;Top Considerations when Evaluating an Ingress Controller for Kubernetes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMwareTanzu/status/1351951632158875652"&gt;VMwareTanzu KubeAcademy’s expert instructors design and deliver each course to give you practical #Kubernetes training. &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/cloudfoundry/status/1351963315614879746"&gt; Learn how CF Protect helps recover data in Cloud Foundry &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>What's New in Azure Spring Cloud after GA?</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/25/what-s-new-in-azure-spring-cloud-after-ga" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-26:4346</id>
    <updated>2021-01-26T03:20:00Z</updated>
    <content type="html">&lt;blockquote&gt;
  &lt;p&gt;This post was written by our friend on the Azure Spring Cloud team, the amazing &lt;a href="https://twitter.com/liangkylie"&gt;Kylie Liang (@liangkylie)&lt;/a&gt;. I interviewed her for the &lt;a href="http://bootifulpodcast.fm"&gt;&lt;em&gt;Bootiful Podcast&lt;/em&gt;&lt;/a&gt; in April 2019, too! -Josh&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2020 was a busy year for Azure Spring Cloud service. Microsoft and VMware co-announced Azure Spring Cloud General Availability (GA). We were excited to see how Azure Spring Cloud helped customers focus on code and let us take care of the underlying infrastructure management, operation, and maintenance. We continue to prioritize our work according to customers’ requests and feedback. For example, 7 more regions were enabled, and Azure Spring Cloud service is now available in &lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-faq?pivots=programming-language-java#in-which-regions-is-azure-spring-cloud-available"&gt;18&lt;/a&gt; regions of Asia Pacific, Australia, Canada, China, Europe, India, Korea, United Arab Emirates, United Kingdom, and the United States. In this blog, I’ll share more about the newest features and enhancements since GA. &lt;/p&gt;&lt;h2&gt;&lt;a href="#full-apm-capabilities-w-application-insights-java-in-process-agent" class="anchor" name="full-apm-capabilities-w-application-insights-java-in-process-agent"&gt;&lt;/a&gt;Full APM Capabilities w/ Application Insights Java in-process Agent&lt;/h2&gt;
&lt;p&gt;Application Insights is an extensible Application Performance Management (APM) service for developers and DevOps professionals. With its latest Java in-process agent you can enjoy full APM functionalities besides distributed tracing. For example, you can monitor real-time live metrics without any code changes and obtain insights into application dependencies – MySQL, PostgreSQL, JDBC, Redis, JMS, Kafka, Netty / WebFlux, etc. Learn more &lt;a href="https://spring.io/blog/2021/01/21/bootiful-application-monitoring-with-azure-spring-cloud"&gt;from here&lt;/a&gt; about effortlessly monitoring applications and dependencies in Azure Spring Cloud!&lt;/p&gt;
&lt;p&gt;As you know, there is always the possibility that a service may be down or having high latency when a service invokes another service. This may lead to exhaustion of the threads as they might be waiting for other requests to complete. With the implementation of the Circuit Breaker pattern, you can prevent failures from cascading and provide fallback behavior until a failing service is restored to normal operation. The new Spring Cloud Circuit Breaker framework unifies all implementations of its metrics data pipeline into Micrometer. Resilience4j is a new option for Spring developers to implement the Circuit Breaker pattern. Resilience4j works well with Spring Boot and using Micrometer libraries, it can produce metrics for monitoring. After enabling &lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-howto-circuit-breaker-metrics"&gt;Application Insights java in-process agent and dimension collection for Resilience4j metrics&lt;/a&gt;, you can collect Spring Cloud Resilience4j Circuit Breaker Metrics and display them in the Metrics blade of Application Insights. &lt;/p&gt;
&lt;img src ="https://github.com/joshlong/blog-images/raw/master/whats-new-in-azure-spring-cloud-after-ga-25-jan-2021/Picture1.png" /&gt;&lt;h2&gt;&lt;a href="#get-outbound-public-ip-to-secure-the-communication-with-external-resources" class="anchor" name="get-outbound-public-ip-to-secure-the-communication-with-external-resources"&gt;&lt;/a&gt;Get outbound public IP to secure the communication with external resources&lt;/h2&gt;
&lt;p&gt;Some network environments are locked down via a Firewall and allow only whitelisted IP addresses inbound to their internal network. Learn how to get &lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-howto-outbound-public-ip"&gt;static outbound public IP addresses&lt;/a&gt; of Azure Spring Cloud applications to communicate with external resources, such as databases, storage, and key vaults. &lt;/p&gt;
&lt;p&gt;Below is an example to whitelist an Azure Spring Cloud app in Azure Database for MySQL. Azure Database for MySQL provides access security using a firewall to protect your data. You can explicitly add all the outbound IPs of your Azure Spring Cloud apps. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To find the outbound public IP addresses currently used by your Azure Spring Cloud service instance in the Azure portal, click &lt;strong&gt;Networking&lt;/strong&gt; in your instance&amp;rsquo;s left-hand navigation pane. They are listed in the &lt;strong&gt;Outbound IP addresses&lt;/strong&gt; field. &lt;br/&gt; &lt;img src ="https://github.com/joshlong/blog-images/raw/master/whats-new-in-azure-spring-cloud-after-ga-25-jan-2021/Picture2.png" /&gt;&lt;/li&gt;
  &lt;li&gt;On the MySQL server page, under Settings heading, click &lt;strong&gt;Connection Security&lt;/strong&gt; and add above outbound IPs one-by-one. &lt;br/&gt;&lt;img src ="https://github.com/joshlong/blog-images/raw/master/whats-new-in-azure-spring-cloud-after-ga-25-jan-2021/Picture3.png" /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;a href="#vs-code-extension-for-azure-spring-cloud" class="anchor" name="vs-code-extension-for-azure-spring-cloud"&gt;&lt;/a&gt;VS Code extension for Azure Spring Cloud&lt;/h2&gt;
&lt;p&gt;Besides feature requests for the Azure Spring Cloud service, we also received requests from developers about how to deploy and manage apps in their familiar environment. You can now use &lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-tutorial-intellij-deploy-apps"&gt;Azure Toolkit for IntelliJ&lt;/a&gt; or &lt;a href="http://asc-vscode/"&gt;Azure Spring Cloud extension for VS Code&lt;/a&gt; to quickly create, manage and deploy apps to Azure Spring Cloud. &lt;/p&gt;
&lt;img src ="https://github.com/joshlong/blog-images/raw/master/whats-new-in-azure-spring-cloud-after-ga-25-jan-2021/Picture4.gif" /&gt;&lt;h2&gt;&lt;a href="#what-is-upcoming" class="anchor" name="what-is-upcoming"&gt;&lt;/a&gt;What is Upcoming&lt;/h2&gt;
&lt;p&gt;Security, elastic scaling, and monitoring are key tenets of Azure Spring Cloud. In the following months, you will see more updates for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Managed Virtual Network&lt;/strong&gt;: allows users to be in control of inbound and outbound network communications for Azure Spring Cloud and enables Azure Spring Cloud to interact with systems in on-premises data centers or Azure services in virtual networks.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Autoscale&lt;/strong&gt;: automates the upscaling or downscaling of the application based on load or schedule – thus providing cost-efficiency and better performance.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;E2E TLS&lt;/strong&gt;: allows users to encrypt and securely transmit sensitive data among applications or from app to the backend.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Azure RBAC&lt;/strong&gt; for managed Spring Cloud Config Server/Service Registry: allows users to authenticate with AAD (Azure Active Directory) token for accessing to managed Spring Cloud Config Server/Service Registry by Azure Spring Cloud service.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Integration with 3rd party APM solutions&lt;/strong&gt;: enables out-of-box experience w/ 3rd party Application Performance Monitoring (APM) tools such as New Relic, App Dynamics and Dynatrace for Azure Spring Cloud apps.&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;a href="#get-started" class="anchor" name="get-started"&gt;&lt;/a&gt;Get Started&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-quickstart?tabs=Azure-CLI&amp;pivots=programming-language-java"&gt;Step by step tutorials&lt;/a&gt;: Learn the basics of Azure Spring Cloud with well-known Spring sample apps.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://docs.microsoft.com/learn/modules/azure-spring-cloud-workshop/"&gt;Online workshop&lt;/a&gt;: Go through tasks to deploy Spring Boot microservices to Azure Spring Cloud with Azure database for MySQL.&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://docs.microsoft.com/azure/spring-cloud/spring-cloud-troubleshoot"&gt;Troubleshooting tips&lt;/a&gt;: Read common tips for troubleshooting Azure Spring Cloud server- and client-side issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are excited about the improving developer experience we are creating for Azure Spring Cloud service. Your feedback has been instrumental in shaping these features, keep the feedback coming. &lt;a href="mailto:AzureSpringCloud-Talk@service.microsoft.com"&gt;Contact us&lt;/a&gt; if you have feedback or questions. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud Task 2.2.5 Release!</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/25/spring-cloud-task-2-2-5-release" />
    <category term="releases" label="Releases" />
    <author>
      <name>Glenn Renfro</name>
    </author>
    <id>tag:spring.io,2021-01-25:4345</id>
    <updated>2021-01-25T16:41:00Z</updated>
    <content type="html">&lt;p&gt;Spring Cloud Task 2.2.5 includes fixes for the following vulnerability:&lt;/p&gt;
&lt;p&gt;CVE-2020-5428&lt;br/&gt;In applications using Spring Cloud Task 2.2.4.RELEASE and below, may contain code that is vulnerable to SQL injection when exercising certain lookup queries in the TaskExplorer. &lt;/p&gt;
&lt;p&gt;Users of Spring Cloud Task 2.2.4.RELEASE and below are encouraged to upgrade to Spring Cloud Task 2.2.5.RELEASE or 2.3.0.&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud Data Flow 2.7.1 Released</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/25/spring-cloud-data-flow-2-7-1-released" />
    <category term="releases" label="Releases" />
    <author>
      <name>Janne Valkealahti</name>
    </author>
    <id>tag:spring.io,2021-01-25:4344</id>
    <updated>2021-01-25T15:00:00Z</updated>
    <content type="html">&lt;p&gt;Spring Cloud Data Flow team is pleased to announce the release of &lt;em&gt;2.7.1&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2.7.1&lt;/em&gt; is a maintenance release fixing following issues:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;UI bug fixes&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Cloudfoundry Java Client&lt;/em&gt; has been updated to &lt;em&gt;4.13.0&lt;/em&gt; fixing its memory leak&lt;/li&gt;
  &lt;li&gt;Using &lt;em&gt;Spring Boot 2.3.7&lt;/em&gt; and &lt;em&gt;Cloud Hoxton.SR9&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Spring Cloud Task&lt;/em&gt; updated to &lt;em&gt;2.2.5&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Dataflow server contains fixes for docker, metrics and some endpoints&lt;/li&gt;
  &lt;li&gt;More detailed list can be found from &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.7.1"&gt;GitHub 2.7.1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is also releases for &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.6.5"&gt;GitHub 2.6.5&lt;/a&gt; and &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow/releases/tag/v2.5.4.RELEASE"&gt;GitHub 2.5.4&lt;/a&gt; with updated &lt;em&gt;Spring Cloud Task&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;These releases fixes &lt;a href="https://tanzu.vmware.com/security/cve-2020-5427"&gt;CVE-2020-5427&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve switched &lt;a href="https://dataflow.spring.io/docs/applications/"&gt;Pre-packaged Applications&lt;/a&gt; in our import links to point to &lt;em&gt;3.x&lt;/em&gt; versions.&lt;/p&gt;&lt;h2&gt;&lt;a href="#stay-in-touch-hellip" class="anchor" name="stay-in-touch-hellip"&gt;&lt;/a&gt;Stay in touch&amp;hellip;&lt;/h2&gt;
&lt;p&gt;As always, we welcome feedback and contributions, so please reach out to us on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud-dataflow"&gt;Stack Overflow&lt;/a&gt; or &lt;a href="https://github.com/spring-cloud/spring-cloud-dataflow/issues"&gt;GitHub&lt;/a&gt; or via &lt;a href="https://gitter.im/spring-cloud/spring-cloud-dataflow"&gt;Gitter&lt;/a&gt;.&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT:  Websockets</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/25/ymnnalft-websockets" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4322</id>
    <updated>2021-01-25T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;The open web has long extended hope to those who wanted a commodity platform to build and deploy services and applications at a large scale. We knew that the web could be compelling once a few things were improved. People could deliver rich clients that would be upgradeable with the refresh of a browser page. They could deliver data-and-multimedia-centric, immersive experiences. We knew that people could do these things if they only had the right paradigm for building web sites and services. But they say that you can&amp;rsquo;t appreciate the sweet without the sour, so the community embarked on a mission to find the &lt;em&gt;absolute worst&lt;/em&gt; approach to building websites and services, and that, kids, is the story of how we got PHP. &lt;/p&gt;
&lt;p&gt;The End.&lt;br/&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;Alright, so there&amp;rsquo;s a &lt;em&gt;little&lt;/em&gt; more to it. In the beginning, there were severe limitations in both the backend and in the client. The problems with the client endured a lot longer than the issues with the backend, however. By the early 2000s, every significant programming language community could build HTTP services, but the client&amp;rsquo;s abilities stagnated. (It was almost like some major force was acting in bad faith to keep the open web from advancing. But why? And who? It&amp;rsquo;s a mystery, one I suppose we&amp;rsquo;ll never resolve&amp;hellip;)&lt;/p&gt;
&lt;p&gt;The open web evolved on its own. It HTTP &lt;code&gt;PATCH&lt;/code&gt; &amp;rsquo;ed itself. In the late 90s, we got PayPal to make secure commerce possible. In the early 2000s, we got the constraint on HTTP called REST (which stands for Really Easy Service Transactions, or was it REcent Software Trend? No. That&amp;rsquo;s not right. Representational State Transfer! That sounds right&amp;hellip;). And then &amp;ldquo;Ajax&amp;rdquo; (no, &lt;em&gt;not&lt;/em&gt; the cleaning product) &lt;a href="http://www.jjg.net/about/"&gt;arrived&lt;/a&gt;, which allowed the client to make requests of the service in-situ, without forcing another HTTP roundtrip to the service to fetch a new page. Lovely. Then we spent an agonizing five years or so trying to find ways to push data from the server to the client instead of sending data to a client in response to the client&amp;rsquo;s request. &lt;/p&gt;
&lt;p&gt;And we did try &lt;em&gt;everything&lt;/em&gt;. There were kludges upon kludges. (Here&amp;rsquo;s a fun fact: janky JavaScript existed &lt;em&gt;years&lt;/em&gt; before Node.js arrived!) Eventually, in 2011, we got a standard that all the HTTP browser vendors and HTTP server vendors could support consistently, and that solved 70% of our needs: &lt;a href="https://en.wikipedia.org/wiki/WebSocket"&gt;WebSockets&lt;/a&gt;. Websockets are awesome! They&amp;rsquo;re the best way to introduce asynchronous communication to a browser-based application. They&amp;rsquo;re fast, they&amp;rsquo;re lightweight and easy to implement. &lt;/p&gt;
&lt;p&gt;While there are many frameworks that you can use to implement WebSocket endpoints, you needn&amp;rsquo;t look any further than Spring as it&amp;rsquo;s supported out of the box for both reactive and non-reactive services. Let&amp;rsquo;s look at a service example using Spring Webflux, the reactive web runtime. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependencies.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reactive Web on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-webflux&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s what I put into my &lt;code&gt;application.properties&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.main.web-application-type=reactive&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.websockets.service;&#xD;
&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.web.reactive.HandlerMapping;&#xD;
import org.springframework.web.reactive.handler.SimpleUrlHandlerMapping;&#xD;
import org.springframework.web.reactive.socket.WebSocketHandler;&#xD;
import org.springframework.web.reactive.socket.WebSocketMessage;&#xD;
import org.springframework.web.reactive.socket.server.support.WebSocketHandlerAdapter;&#xD;
import reactor.core.publisher.Flux;&#xD;
&#xD;
import java.util.Map;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		System.setProperty(&amp;quot;spring.profiles.active&amp;quot;, &amp;quot;wsserver&amp;quot;);&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	SimpleUrlHandlerMapping greetingsHm() {&#xD;
		return new SimpleUrlHandlerMapping(Map.of(&amp;quot;/ws/greetings&amp;quot;, greetingsWsh()), 10);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	WebSocketHandler greetingsWsh() {&#xD;
		return session -&amp;gt; {&#xD;
&#xD;
			Flux&amp;lt;WebSocketMessage&amp;gt; out = session.receive().map(WebSocketMessage::getPayloadAsText)&#xD;
					.flatMap(name -&amp;gt; Flux.just(&amp;quot;Hi, &amp;quot; + name).map(session::textMessage));&#xD;
&#xD;
			return session.send(out);&#xD;
		};&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;SimpleUrlHandlerMapping&lt;/code&gt; maps the &lt;code&gt;WebSocketHandler&lt;/code&gt; to an HTTP URI. The &lt;code&gt;WebSocketHandler&lt;/code&gt; provides the reactive WebSocket endpoint logic, turning the incoming payload (a name) into a greeting (&lt;code&gt;Hi, NAME!&lt;/code&gt;) to be sent to the client.&lt;/p&gt;
&lt;p&gt;Now, I&amp;rsquo;m going to do something that I would not normally do. If there were &lt;em&gt;any&lt;/em&gt; other way, friends, I would surely prefer that alternative to this rather unbecoming way forward. I would not do this in polite company, but I feel there&amp;rsquo;s no other way to get this done, no other way to demonstrate how trivial it can be to communicate with a WebSocket endpoint. I do not do this lightly. &lt;/p&gt;
&lt;p&gt;I.. am going to use JavaScript:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;    window.addEventListener(&amp;#39;load&amp;#39;, () =&amp;gt; {&#xD;
        const ws = new WebSocket(&amp;#39;ws://localhost:8080/ws/greetings&amp;#39;)&#xD;
        ws.addEventListener(&amp;#39;open&amp;#39;, () =&amp;gt; {&#xD;
            ws.send(&amp;#39;JavaScript Fans&amp;#39;)&#xD;
        })&#xD;
        ws.addEventListener(&amp;#39;message&amp;#39;, (message) =&amp;gt; {&#xD;
            console.log(message.data)&#xD;
        })&#xD;
    })&#xD;
&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the example, we set up a &lt;code&gt;WebSocket&lt;/code&gt; object in JavaScript, register a callback to send data on the WebSocket when it was finally ready, and register another callback for any replies that arrive. Go to your browser&amp;rsquo;s &lt;em&gt;Developer Tools&lt;/em&gt; (instructions vary for each browser, but you might try &lt;code&gt;OPTION&lt;/code&gt; + &lt;code&gt;CMD&lt;/code&gt; + &lt;code&gt;I&lt;/code&gt; if you&amp;rsquo;re on a Mac and using Chrome or Firefox) and then choose &lt;code&gt;Console&lt;/code&gt;. You&amp;rsquo;ll see the response from the WebSocket endpoint there. &lt;/p&gt;
&lt;p&gt;With more code, we can also talk to that service using the Spring &lt;code&gt;WebSocketClient&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependencies.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reactive Web on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-webflux&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.websockets.client;&#xD;
&#xD;
import lombok.SneakyThrows;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.web.reactive.socket.WebSocketMessage;&#xD;
import org.springframework.web.reactive.socket.client.ReactorNettyWebSocketClient;&#xD;
import org.springframework.web.reactive.socket.client.WebSocketClient;&#xD;
import reactor.core.publisher.Mono;&#xD;
&#xD;
import java.net.URI;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	@SneakyThrows&#xD;
	public static void main(String[] args) {&#xD;
		System.setProperty(&amp;quot;spring.profiles.active&amp;quot;, &amp;quot;wsclient&amp;quot;);&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
		Thread.sleep(5_000);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	WebSocketClient webSocketClient() {&#xD;
		return new ReactorNettyWebSocketClient();&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(WebSocketClient client) {&#xD;
		return event -&amp;gt; client.execute(URI.create(&amp;quot;ws://localhost:8080/ws/greetings&amp;quot;), webSocketSession -&amp;gt; {&#xD;
			WebSocketMessage world = webSocketSession.textMessage(&amp;quot;Spring Fans&amp;quot;);&#xD;
			return webSocketSession.send(Mono.just(world))&#xD;
					.thenMany(webSocketSession.receive().map(WebSocketMessage::getPayloadAsText).log()).then();&#xD;
		})//&#xD;
				.subscribe();&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s what I put into my &lt;code&gt;application.properties&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.main.web-application-type=none
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;WebSockets make our browser-based clients more lively. I quite prefer RSocket for service-to-service communication, however. &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast - Spring Tools lead Martin Lippert on sustainable software</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/21/a-bootiful-podcast-spring-tools-lead-martin-lippert-on-sustainable-software" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-22:4343</id>
    <updated>2021-01-22T03:26:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this installment &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Spring Tools lead &lt;a href="https://twitter.com/martinlippert"&gt;Martin Lippert (@martinlippert)&lt;/a&gt; about sustainability in software, specifically, and I.T., generally. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the slides to Martin&amp;rsquo;s talk &lt;a href="https://speakerdeck.com/martinlippert/sustainability-in-software-engineering-eclipsecon-2020-edition"&gt;&lt;em&gt;Sustainability in Software Engineering&lt;/em&gt;&lt;/a&gt;, as presented at EclipseCON 2020&lt;/li&gt;
  &lt;li&gt;and &lt;a href="https://www.youtube.com/watch?v=ZsJVhEy0ka4"&gt;here is the video for that talk&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe title="Spring Tools lead Martin Lippert on sustainable software" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/frsdq-f846d9?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Boot 2.5.0-M1 available now</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/21/spring-boot-2-5-0-m1-available-now" />
    <category term="releases" label="Releases" />
    <author>
      <name>Madhura Bhave</name>
    </author>
    <id>tag:spring.io,2021-01-22:4342</id>
    <updated>2021-01-22T02:36:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the team and everyone that contributed, I am pleased to announce that the first milestone of Spring Boot 2.5 has been released and is available from our &lt;a href="https://repo.spring.io/milestone/"&gt;milestone repository&lt;/a&gt;. This release closes &lt;a href="https://github.com/spring-projects/spring-boot/releases/tag/v2.5.0-M1"&gt;over 130 issues and pull requests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Highlights of this first milestone include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Support for GET requests to the startup endpoint&lt;/li&gt;
  &lt;li&gt;Security improvements to the info endpoint&lt;/li&gt;
  &lt;li&gt;Preliminary support for Java 16&lt;/li&gt;
  &lt;li&gt;Spring Integration 5.5.0 M1&lt;/li&gt;
  &lt;li&gt;Spring Data 2021.0.0 M1&lt;/li&gt;
  &lt;li&gt;Spring Security 5.5.0 M1&lt;/li&gt;
  &lt;li&gt;Spring Session 2021.0.0 M1&lt;/li&gt;
  &lt;li&gt;Spring HATEOAS 1.3.0 M1&lt;/li&gt;
  &lt;li&gt;Numerous other dependency upgrades&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a complete list of changes and upgrade instructions, please see the &lt;a href="https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-2.5.0-M1-Release-Notes"&gt;Spring Boot 2.5 Release Notes&lt;/a&gt; on the wiki and the &lt;a href="https://docs.spring.io/spring-boot/docs/2.5.0-M1/reference/html/"&gt;updated reference documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want to get started with 2.5 and try out the new features, you can bootstrap a new project on &lt;a href="https://start.spring.io/#!type=maven-project&amp;language=java&amp;platformVersion=2.5.0.M1&amp;packaging=jar&amp;jvmVersion=11&amp;groupId=com.example&amp;artifactId=demo&amp;name=demo&amp;description=Demo%20project%20for%20Spring%20Boot&amp;packageName=com.example.demo"&gt;start.spring.io&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://spring.io/projects/spring-boot/"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-boot"&gt;GitHub&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-boot/issues"&gt;Issues&lt;/a&gt; | &lt;a href="https://docs.spring.io/spring-boot/docs/2.5.0-M1/reference/html/"&gt;Documentation&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-boot"&gt;Stack Overflow&lt;/a&gt; | &lt;a href="https://gitter.im/spring-projects/spring-boot"&gt;Gitter&lt;/a&gt;&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Bootiful Application Monitoring with Azure Spring Cloud</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/21/bootiful-application-monitoring-with-azure-spring-cloud" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-21:4341</id>
    <updated>2021-01-21T18:15:00Z</updated>
    <content type="html">&lt;blockquote&gt;
  &lt;p&gt;This is a guest post authored by our friend, Microsoft&amp;rsquo;s Asir Vedamuthu Selvasingh &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Hi, Spring fans! We are excited to announce that Application Performance Monitoring (APM) is now fully integrated into Azure Spring Cloud, powered by Application Insights.&lt;/p&gt;
&lt;p&gt;Azure Spring Cloud is jointly built, operated, and supported by Microsoft and VMware. It is a fully managed service for Spring Boot applications that lets you focus on building the applications that run your business without the hassle of managing infrastructure. &lt;/p&gt;
&lt;p&gt;APM in Azure Spring Cloud offers in-depth performance monitoring for your Spring applications without requiring ANY code changes, recompiling, retesting, or redeployment. APM on Azure Spring Cloud is so seamless that you get the insights on your applications just out of the box. You do not have to do ANYTHING - just deploy your applications and the monitoring data starts flowing. The benefits you get with application monitoring are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Visibility into all your applications with &lt;strong&gt;distributed tracing&lt;/strong&gt;, including paths of operation requests from origins to destinations and insights into applications that are operating correctly and those with bottlenecks.&lt;/li&gt;
  &lt;li&gt;Logs, exceptions, and metrics in the context of call paths offer &lt;strong&gt;meaningful insights and actionable information&lt;/strong&gt; to speed root cause analysis.&lt;/li&gt;
  &lt;li&gt;Insights into application &lt;strong&gt;dependencies&lt;/strong&gt; – SQL Database, MySQL, PostgreSQL, MariaDB, JDBC, MongoDB, Cassandra, Redis, JMS, Kafka, Netty / WebFlux, etc.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Performance data&lt;/strong&gt; for every call into operations exposed by applications, including data-like request counts, response times, CPU usage, and memory.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Custom metrics&lt;/strong&gt; conveniently auto-collected through Micrometer, allowing you to publish custom performance indicators or business-specific metrics and visualize deeper application and business insights.&lt;/li&gt;
  &lt;li&gt;Ability to &lt;strong&gt;browse, query, and alert on application metrics and logs&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While both Azure Spring Cloud and Application Insights Java agent are generally available, their integration for out of the box monitoring is in preview.&lt;/p&gt;
&lt;p&gt;You can enable the Java in-process monitoring agent when you create or update Azure Spring Cloud:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint shell"&gt;az spring-cloud create --name ${SPRING_CLOUD_SERVICE} &#xD;
        --sku standard --enable-java-agent &#xD;
        --resource-group ${RESOURCE_GROUP} &#xD;
        --location ${REGION}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, you can open Application Insights created by Azure Spring Cloud and start monitoring applications and their dependencies – we will illustrate this using a &lt;a href="https://github.com/Azure-Samples/spring-petclinic-microservices"&gt;distributed version of Spring Petclinic&lt;/a&gt;. Navigate to the &lt;code&gt;Application Map&lt;/code&gt; blade where you can see an incredible, holistic view of microservices that shows applications that are operating correctly (green) and those with bottlenecks (red) [Figure 1]. Developers can easily identify issues in their applications and quickly troubleshoot and fix them.&lt;/p&gt;
&lt;figcaption &gt; Figure 1 - Microservice transactions in Application Insights &lt;/figcaption&gt;
&lt;img  width="700" src ="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/distributed-tracking-new-ai-agent.jpg" /&gt;
&lt;p&gt;Navigate to the &lt;code&gt;Performance&lt;/code&gt; blade where you can see response times and request counts for operations exposed by your applications [Figure 2]. &lt;/p&gt;
&lt;figcaption &gt; &#xD;
Figure 2 – Performance of operations exposed by applications &lt;/figcaption&gt;
&lt;img width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-performance.jpg" /&gt;
&lt;p&gt;Navigate to the &lt;code&gt;Dependencies&lt;/code&gt; tab in the &lt;code&gt;Performance&lt;/code&gt; blade where you can see all your dependencies and their response times and request counts [Figure 3]. &lt;/p&gt;
&lt;figcaption&gt;Figure 3 – Performance of application dependencies&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-insights-on-dependencies.jpg" /&gt;
&lt;p&gt;You can click a SQL call or a dependency to see the full end-to-end transaction in context [Figure 4].&lt;/p&gt;
&lt;figcaption&gt;&#xD;
Figure 4 – End-to-end application to SQL call transaction details&#xD;
&lt;/figcaption&gt;
&lt;img width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-end-to-end-transaction-details.jpg" /&gt;
&lt;p&gt;Navigate to the &lt;code&gt;Exceptions&lt;/code&gt; tab in the &lt;code&gt;Failures&lt;/code&gt; blade to see a collection of exceptions thrown by applications [Figure 5].&lt;/p&gt;
&lt;figcaption&gt;Figure 5 – Exceptions thrown by applications&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-failures-exceptions.jpg" /&gt;
&lt;p&gt;Simply select an exception and drill in for meaningful insights and actionable stack trace [Figure 6].&lt;/p&gt;
&lt;figcaption&gt;Figure 6 – End-to-end transaction details for an application exception&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/end-to-end-transaction-details.jpg" /&gt;
&lt;p&gt;Navigate to the &lt;code&gt;Metrics&lt;/code&gt; blade to see all the metrics contributed by Spring Boot applications, Spring Cloud modules, and their dependencies. The chart below showcases &lt;code&gt;gateway-requests&lt;/code&gt; contributed by Spring Cloud Gateway and &lt;code&gt;hikaricp_connections&lt;/code&gt; contributed by JDBC [Figure 7]. Similarly, you can aggregate Spring Cloud Resilience4J metrics and visualize them.&lt;/p&gt;
&lt;figcaption&gt;Figure 7 – Metrics contributed by Spring modules&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-metrics.jpg" /&gt;
&lt;p&gt;Spring Boot applications register a lot of core metrics – JVM, CPU, Tomcat, Logback, etc. You can use Micrometer to contribute your own custom metrics, say using the &lt;code&gt;@Timed&lt;/code&gt; Micrometer annotation at the class level. You can then visualize those custom metrics in Application Insights. As an example, see how pet owners, pets, and their clinical visits are tracked by custom metrics below – you can also see how the pattern changes at 9 PM because applications are driving higher utilization when autoscaling kicked in [Figure 8].&lt;/p&gt;
&lt;figcaption&gt;Figure 8 – Custom metrics published by user applications&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-custom-metrics.jpg" /&gt;
&lt;p&gt;You can use the Availability Test feature in Application Insights to monitor the availability of applications in Azure Spring Cloud. This is a recurring test to monitor the availability and responsiveness of applications at regular intervals from anywhere across the globe. It can proactively alert you if your applications are not responding or if they respond too slowly. The chart below shows availability tests from across North America – West US, South Central, Central US and East US [Figure 9].&lt;/p&gt;
&lt;figcaption&gt;Figure 9 – Availability of application endpoints across time&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-availability.jpg" /&gt;
&lt;p&gt;Navigate to the &lt;code&gt;Live Metrics&lt;/code&gt; blade where you can see live metrics practically in real-time, within only one second [Figure 10]. &lt;/p&gt;
&lt;figcaption&gt;Figure 10 – Real-time metrics&#xD;
&lt;/figcaption&gt;
&lt;img  width="700" src="https://github.com/Azure-Samples/spring-petclinic-microservices/raw/azure/media/petclinic-microservices-live-metrics.jpg" /&gt;
&lt;p&gt;Application Insights Java agent is based on &lt;a href="https://opentelemetry.io/docs/java/automatic_instrumentation/"&gt;OpenTelemetry&lt;/a&gt; auto instrumentation effort, where Microsoft collaborates with other brightest minds of the APM space.&lt;/p&gt;&lt;h2&gt;&lt;a href="#build-your-solutions-and-monitor-them-today" class="anchor" name="build-your-solutions-and-monitor-them-today"&gt;&lt;/a&gt;Build your solutions and monitor them today!&lt;/h2&gt;
&lt;p&gt;Azure Spring Cloud abstracts away the complexity of infrastructure management and Spring Cloud middleware management, so you can focus on building your business logic and let Azure take care of dynamic scaling, patches, security, compliance, and high availability. With a few steps, you can provision Azure Spring Cloud, create applications, deploy, and scale Spring Boot applications, and start monitoring in minutes. We will continue to bring more developer-friendly and enterprise-ready features to Azure Spring Cloud.&lt;/p&gt;
&lt;p&gt;We would love to hear how you are building impactful solutions using Azure Spring Cloud. Get started today – deploy Spring applications to Azure Spring Cloud using &lt;a href="https://docs.microsoft.com/en-us/azure/spring-cloud/spring-cloud-quickstart?tabs=Azure-CLI&amp;pivots=programming-language-java"&gt;quickstart&lt;/a&gt;!&lt;/p&gt;&lt;h2&gt;&lt;a href="#resources" class="anchor" name="resources"&gt;&lt;/a&gt;Resources:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Get started with your next Spring Boot-based project at &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Learn using an &lt;a href="https://docs.microsoft.com/en-us/learn/modules/azure-spring-cloud-workshop/"&gt;MS Learn module&lt;/a&gt; or &lt;a href="https://github.com/microsoft/azure-spring-cloud-training"&gt;self-paced workshop&lt;/a&gt; on GitHub&lt;/li&gt;
  &lt;li&gt;Learn &lt;a href="https://docs.microsoft.com/en-us/azure/spring-cloud/"&gt;more&lt;/a&gt; about implementing solutions on Azure Spring Cloud&lt;/li&gt;
  &lt;li&gt;Learn &lt;a href="https://docs.microsoft.com/en-us/azure/spring-cloud/spring-cloud-howto-application-insights"&gt;more&lt;/a&gt; about Application Insights &lt;a href="https://docs.microsoft.com/en-us/azure/azure-monitor/app/java-in-process-agent"&gt;Java in-process&lt;/a&gt; agent in Azure Spring Cloud, including &lt;a href="https://docs.microsoft.com/en-us/azure/spring-cloud/spring-cloud-howto-circuit-breaker-metrics"&gt;Spring Cloud Resilience4J Circuit Breaker&lt;/a&gt; metrics&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/Azure-Samples/spring-petclinic-microservices"&gt;Deploy&lt;/a&gt; a distributed version of Spring Petclinic built with Spring Cloud&lt;/li&gt;
  &lt;li&gt;Migrate your &lt;a href="https://docs.microsoft.com/en-us/azure/developer/java/migration/migrate-spring-boot-to-azure-spring-cloud"&gt;Spring Boot&lt;/a&gt;, &lt;a href="https://docs.microsoft.com/en-us/azure/developer/java/migration/migrate-spring-cloud-to-azure-spring-cloud"&gt;Spring Cloud&lt;/a&gt; and &lt;a href="https://docs.microsoft.com/en-us/azure/developer/java/migration/migrate-tomcat-to-azure-spring-cloud"&gt;Tomcat&lt;/a&gt; applications to Azure Spring Cloud&lt;/li&gt;
  &lt;li&gt;Wire Spring applications to &lt;a href="https://docs.microsoft.com/en-us/azure/developer/java/spring-framework/"&gt;interact with Azure services&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;For feedback and questions, &lt;a href="mailto:AzureSpringCloud-Talk@service.microsoft.com"&gt;please e-mail us&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT:  Dimensional Metrics Accumulation with Micrometer</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/20/ymnnalft-dimensional-metrics-accumulation-with-micrometer" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4321</id>
    <updated>2021-01-20T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s 3 AM. Do you know where your production KPI Metrics are? You can&amp;rsquo;t improve that you can&amp;rsquo;t measure, and metrics are an important part of this. Without metrics, we&amp;rsquo;re utterly and hopelessly lost, trapped in a spiraling death-march project with no sign or hope of any improvement! Tremble, ye wretched and miserable developer! Without metrics, we&amp;rsquo;re blind, and there&amp;rsquo;s nothing funny about that, so instead, here&amp;rsquo;s a photo of my daughter&amp;rsquo;s adorable little guinea pig, Kai:&lt;/p&gt;
&lt;img src="https://pbs.twimg.com/media/Ef7FS3yUEAEE5oF?format=jpg&amp;name=large" width = "500" /&gt;
&lt;p&gt;Metrics give us a way to describe specific facts about our system - it lets us quantify essential data, which is nice since there are all sorts of things to count and quantify: &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;how many people have clicked the &amp;lsquo;check out&amp;rsquo; button?&lt;/li&gt;
  &lt;li&gt;How many people have signed up?&lt;/li&gt;
  &lt;li&gt;How long are requests to a particular endpoint taking?&lt;/li&gt;
  &lt;li&gt;How many people are experiencing errors?&lt;/li&gt;
  &lt;li&gt;What is the average time for a given request? (Or, more usefully, what&amp;rsquo;s the 99th percentile of a given request?&lt;/li&gt;
  &lt;li&gt;Bob, did you get your TPS reports in? Oh _ c&amp;rsquo;mon_, Bob! We talked about this! You said you&amp;rsquo;d get it in by close-of-business Tuesday, you absolute scoundrel!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There&amp;rsquo;s a real art to learning about which metrics to capture and which are irrelevant. Whole careers, even! &amp;ldquo;Growth hacker,&amp;rdquo; anyone? Not all metrics are created equal. &lt;em&gt;Growth hackers&lt;/em&gt; care about metrics. Product managers will care about metrics. The business will care about metrics. Your platform can care about metrics. &lt;em&gt;You&lt;/em&gt; should care about metrics. And why not? All the data&amp;rsquo;s there for the taking, but you&amp;rsquo;ll need a robust framework to help you. Writing code to instrument your code and capture metrics is only half the battle. Once captured, you&amp;rsquo;ll want (need!) to store and analyze the metrics. To do so, you&amp;rsquo;ll use a time series database - something like &lt;a href="https://tanzu.vmware.com/observability"&gt;VMWare&amp;rsquo;s Wavefront&lt;/a&gt;, &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt;, &lt;a href="https://github.com/Netflix/atlas"&gt;Netflix Atlas&lt;/a&gt;, &lt;a href="https://www.datadoghq.com/"&gt;DataDog&lt;/a&gt;, &lt;a href="http://instana.com"&gt;Instana&lt;/a&gt;, etc., to then visualize and analyze that data. You&amp;rsquo;ll need a robust framework that supports capturing all sorts of metrics (timers, counters, histograms, averages, etc.) in all sorts of contexts and then emitting those metrics to all sorts of time series databases (TSDBs). &lt;/p&gt;
&lt;p&gt;Enter &lt;a href="http://micrometer.io"&gt;Micrometer&lt;/a&gt;. Micrometer allows you to instrument your code with dimensional metrics with a vendor-neutral interface and decide at the last step which monitoring system you&amp;rsquo;d like to use. Instrumenting your core library code with Micrometer allows the libraries to be included in applications that ship metrics to different backends. Spring Boot provides the Actuator module to support capturing and observing different aspects of an application. It sports endpoints of things like an application&amp;rsquo;s health, the thread dumps, and countless other things. It has an endpoint, &lt;code&gt;/actuator/metrics&lt;/code&gt;, that depends on Micrometer, giving you an at-a-glance view of the metrics being captured by your Spring Boot application, independent of whether you&amp;rsquo;re also publishing those metrics to a TSDB. &lt;/p&gt;
&lt;p&gt;Keep in mind that Spring depends on Micrometer, but Micrometer does not depend on Spring. Many libraries instrument themselves using the Micrometer SPI. All you need to do is add integration with a TSDB. Here are some of the third-party libraries that emit metrics with Micrometer: Javalin, HikariCP, the RabbitMQ Java client, Redisson, the Brave distributed tracing client, Netflix Spinnaker, the Netty-powered, non-blocking, Armeria framework, the Alibaba Nacos client, Apache Geode, the Microsoft Azure Spring Boot integrations, Resilience4J, the reactive Playtika Feign-client, Openrewrite, Apache Camel, the Couchbase Java DCP client, and literally hundreds of others. Oh, did I mention that countless modules in the Spring ecosystem support it as well? Yes, Micrometer truly is &lt;em&gt;everywhere&lt;/em&gt; you want to be! &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re using Spring, of course, so it&amp;rsquo;s easier to just add the Spring Boot Actuator module to the build. If you want to support a particular TSBD, you&amp;rsquo;ll have to bring in the specific module for that particular integration. Some Micrometer integrations come complete with a full Spring Boot integration, too, so you can use those if you want in lieu of the direct Micrometer integration. VMware Wavefront is one such TSDB that ships with extensive and rich integration with Spring Boot, so I&amp;rsquo;ll bring in that superset integration here.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at a simple service. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependencies.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
  &lt;p&gt;Actuator on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-actuator&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
  &lt;li&gt;
  &lt;p&gt;Wavefront on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;com.wavefront&lt;/code&gt; : &lt;code&gt;wavefront-spring-boot-starter&lt;/code&gt; &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this example, I create two counter metrics for the statistic about my coffee consumption for the day. I add one extra dimension to the data: whether the coffee had caffeine or not.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.metrics;&#xD;
&#xD;
import io.micrometer.core.instrument.Counter;&#xD;
import io.micrometer.core.instrument.MeterRegistry;&#xD;
import io.micrometer.core.instrument.Timer;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
&#xD;
import java.time.Duration;&#xD;
import java.util.concurrent.TimeUnit;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		System.setProperty(&amp;quot;spring.profiles.active&amp;quot;, &amp;quot;metrics&amp;quot;);&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(MeterRegistry registry) {&#xD;
		return event -&amp;gt; {&#xD;
&#xD;
			// http://localhost:8080/actuator/metrics/coffees&#xD;
			String metricsKey = &amp;quot;coffees&amp;quot;;&#xD;
			Counter decaffeinated = registry.counter(metricsKey, &amp;quot;caffeine&amp;quot;, &amp;quot;false&amp;quot;);&#xD;
			Counter caffeinated = registry.counter(metricsKey, &amp;quot;caffeine&amp;quot;, &amp;quot;true&amp;quot;);&#xD;
&#xD;
			for (int i = 0; i &amp;lt; (int) (Math.random() * 10); i++)&#xD;
				caffeinated.increment();&#xD;
&#xD;
			for (int i = 0; i &amp;lt; (int) (Math.random() * 10); i++)&#xD;
				decaffeinated.increment();&#xD;
&#xD;
			System.out.println(&amp;quot;caffeinated: &amp;quot; + caffeinated.count());&#xD;
			System.out.println(&amp;quot;decaffeinated: &amp;quot; + decaffeinated.count());&#xD;
&#xD;
			// http://localhost:8080/actuator/metrics/message-print&#xD;
			Timer timer = registry.timer(&amp;quot;message-print&amp;quot;);&#xD;
&#xD;
			for (int i = 0; i &amp;lt; 10; i++)&#xD;
				timer.record(Duration.ofMillis((long) (Math.random() * (10 * 1000))));&#xD;
&#xD;
			System.out.println(&amp;quot;message-print: &amp;quot; + timer.totalTime(TimeUnit.SECONDS));&#xD;
		};&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s what I put into my &lt;code&gt;application.properties&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.main.web-application-type=reactive&#xD;
management.endpoints.web.exposure.include=*&#xD;
management.endpoint.metrics.enabled=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In most entries in this series, I mention possible alternatives to the library under discussion. I don&amp;rsquo;t want to do that here because I haven&amp;rsquo;t really found anything that comes close to Micrometer, and it&amp;rsquo;d be disingenuous if I said I had. Micrometer is a much better solution. Most of the other metrics frameworks you&amp;rsquo;ll find either fail to integrate with as many solutions as Micrometer or, worse, don&amp;rsquo;t support &lt;em&gt;dimensional metrics&lt;/em&gt;. Dimensional metrics refer to metric data that has a variety of attributes (dimensions) attached. These attributes could include duration-related attributes (start and stop time), IDs, metadata attached with the client context, the region of the request, information about the client, information about the endpoint being invoked, host, status code, etc. This amount of detail allows for in-depth analysis and querying. Dimensional metrics mean that it&amp;rsquo;s easier to capture metrics, and it&amp;rsquo;s easier to then drill down into the metrics in an unforeseen way later. Win-win! &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - January 19th, 2021</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/19/this-week-in-spring-january-19th-2021" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-19:4340</id>
    <updated>2021-01-19T21:53:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! We&amp;rsquo;ve got a lot to cover so let&amp;rsquo;s get to it.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=lgyo9c9zdrg&amp;feature=share"&gt;What’s new in Spring Boot 2.4&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/14/a-bootiful-podcast-spring-cloud-stream-lead-oleg-zhurakousky"&gt;A Bootiful Podcast - Spring Cloud Stream lead Oleg Zhurakousky&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/18/ymnnalft-easy-rpc-with-rsocket"&gt;YMNNALFT: Easy RPC with RSocket&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/13/ymnnalft-express-yourself-with-spel"&gt;YMNNALFT: Express Yourself with SpEL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/brungarc/status/1349910675561324549?s=12"&gt;Check out the Sentry Spring Boot starter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=vg7rw4upn3a&amp;feature=share"&gt;Developing Spring Boot applications with Kotlin on Google Cloud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://openjdk.java.net/jeps/8251554"&gt;JEP draft: Primitive Objects (Preview)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/stilkov/status/1351162660453310468?s=12"&gt;@__jpr has integrated Hotwire into a Spring Boot environment &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://inside.java/2021/01/16/new-loom-ea-builds/"&gt;New Loom Early Access Build&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UJVyGUaHUEg"&gt;No matter what the usecase, Azure has your Java apps covered&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blog.jetbrains.com/kotlin/2021/01/results-of-the-first-kotlin-multiplatform-survey/"&gt;On the JetBrains Blog: Results of the First Kotlin Multiplatform Survey &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/14/spring-boot-2-2-13-available-now"&gt;Spring Boot 2.2.13 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/14/spring-boot-2-3-8-available-now"&gt;Spring Boot 2.3.8 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/14/spring-boot-2-4-2-available-now"&gt;Spring Boot 2.4.2 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/13/spring-data-2020-0-3-and-2021-0-m2-released"&gt;Spring Data 2020.0.3 and 2021.0-M2 released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/13/the-latest-on-azure-active-directory-integration"&gt;The latest on Azure Active Directory integration&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT: Easy RPC with RSocket</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/18/ymnnalft-easy-rpc-with-rsocket" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4320</id>
    <updated>2021-01-18T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;Integrating two services separated by a common, potentially volatile, and overwhelmed network is one of the most challenging computer science problems. &lt;/p&gt;
&lt;p&gt;Quick aside: the most challenging problem in computer science is, of course, vertical layouts in CSS. &lt;/p&gt;
&lt;img src="https://blog.appstudio.dev/wp-content/uploads/2018/12/css.gif" /&gt;
&lt;p&gt;You could write a whole book about the different ways to integrate disparate systems and services. But, &lt;a href="https://twitter.com/ghohpe"&gt;Gregor Hohpe&lt;/a&gt; and &lt;a href="https://twitter.com/bobby_woolf"&gt;Bobby Woolf&lt;/a&gt; already did just that with their &lt;a href="https://www.amazon.com/Enterprise-Integration-Patterns-Designing-Deploying/dp/0321200683"&gt;&lt;em&gt;Enterprise Integration Patterns&lt;/em&gt;&lt;/a&gt; book, so I&amp;rsquo;ll use one of their lists.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Messaging&lt;/em&gt; is where a producer sends a message (with an enveloper and a payload) to a reliable, intermediary broker. That broker acts as the delivery service for messages between the producer and the consumer.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;RPC&lt;/em&gt;, or Remote Proxy Calls.., not that&amp;rsquo;s not it. Risky Procedure Calls? No&amp;hellip; Relatively Painless Calamities? No&amp;hellip; Remote Procedure Calls! That&amp;rsquo;s the stuff. RPC is where a consumer invokes methods (through some sort of network protocol like SOAP-RPC, Hessian, Burlap, Spring&amp;rsquo;s own HTTP Invoker, XML RPC, EJBs, RMI, DCOM, CORBA, etc.) on remote objects. The experience is meant to feel like invoking methods on a local object in the same virtual machine.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;File Transfer&lt;/em&gt; is where a producer transmits a file to a shared, agreed-upon (network) file system, and the consumer consumes messages deposited there. This is the basis of so many batch processes today. If you haven&amp;rsquo;t, you should check out Spring Batch. 9/10 dentists agree: Spring Batch keeps teeth clean and integration processes lean. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Shared databases&lt;/em&gt; is where a producer and a consumer read data from the same table (not recommended). Indeed, this one is a bit of an antipattern at this point, particularly in the context of microservices. &lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s definitely a discussion to be had around RPC&amp;rsquo;s merits versus messaging as a way to reliably integrate a producer and a consumer, but &lt;em&gt;this&lt;/em&gt; is not that discussion because I think I&amp;rsquo;ve found the best compromise: reactive, payload-agnostic, lightning-quick, observable, RSocket. &lt;a href="http://RSocket.io"&gt;RSocket&lt;/a&gt; is a binary protocol initially developed by engineers at Netflix who left and continued their work at Facebook. The protocol is built for scale &lt;em&gt;and&lt;/em&gt; speed and circumvents many of the limitations of HTTP 1-2 and gRPC. It is an endlessly exciting protocol for a ton of reasons: &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;it supports proper bidirectional communication&lt;/li&gt;
  &lt;li&gt;it supports many different message exchange patterns beyond mere request/response&lt;/li&gt;
  &lt;li&gt;it supports metadata to propagate out-of-band-information like tokens&lt;/li&gt;
  &lt;li&gt;it reifies the Reactive Streams specification concepts at the network protocol level (backpressure! On the wire! Huzzah!)&lt;/li&gt;
  &lt;li&gt;It has a cool &lt;code&gt;.io&lt;/code&gt; domain, which everybody knows is critical to the success of technologies destined for the cloud&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s a message envelope-centric protocol, but it is trivial to use, and it&amp;rsquo;s even more trivial to live that RPC-life if you want to.&lt;/p&gt;
&lt;p&gt;There are numerous clients available for various languages, including Java. The Java client is built on top of &lt;a href="http://ProjectReactor.io"&gt;Project Reactor&lt;/a&gt;. It would&amp;rsquo;ve been &lt;em&gt;trivial&lt;/em&gt; - &lt;em&gt;TRIVIAL! I say&lt;/em&gt; - to integrate RSocket into a Spring application even if there were no native support in Spring itself. But there &lt;em&gt;is&lt;/em&gt; native support in Spring itself, and it&amp;rsquo;s incredible. The integration uses the same component model as the original WebSocket support from Spring Framework 4 uses. &lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at a simple example service. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependencies.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;RSocket on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-rsocket&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.rpc.server;&#xD;
&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.messaging.handler.annotation.DestinationVariable;&#xD;
import org.springframework.messaging.handler.annotation.MessageMapping;&#xD;
import org.springframework.messaging.handler.annotation.Payload;&#xD;
import org.springframework.stereotype.Controller;&#xD;
&#xD;
import java.util.Locale;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		System.setProperty(&amp;quot;spring.profiles.active&amp;quot;, &amp;quot;rpcserver&amp;quot;);&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
}&#xD;
&#xD;
@Controller&#xD;
class GreetingsController {&#xD;
&#xD;
	@MessageMapping(&amp;quot;greetings.{lang}&amp;quot;)&#xD;
	String greet(@DestinationVariable(&amp;quot;lang&amp;quot;) Locale lang, @Payload String name) {&#xD;
		System.out.println(&amp;quot;locale: &amp;quot; + lang.getLanguage());&#xD;
		return &amp;quot;Hello, &amp;quot; + name + &amp;quot;!&amp;quot;;&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s what I put into my &lt;code&gt;application.properties&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.rsocket.server.port=8888&#xD;
spring.main.web-application-type=none
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A controller is an object with methods, like RPC, but the client isn&amp;rsquo;t strictly speaking obliged to wait for a response. It can background the thread or disconnect entirely. Win-win. The protocol is more envelope-and-payload-centric behind the scenes than the component model lets on, so we get the best of both worlds. &lt;/p&gt;
&lt;p&gt;Our service is up and running. If you want to invoke it, you can use &lt;a href="https://github.com/making/rsc"&gt;the handy-dandy &lt;code&gt;rsc&lt;/code&gt; CLI&lt;/a&gt;. &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint shell"&gt;rsc tcp://localhost:8888  -r greetings.en -d &amp;#39;Josh&amp;#39; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should get output like this: &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint shell"&gt;Hello, Josh!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That might be enough, but most of us will want to talk to our RSocket services from our client code. There are clients from several different programming languages, including, but not limited to, JavaScript, Go, .NET (C#), Rust, C++, Ruby, Python, and more. (and, worst case, you can always wrap the C++ or Java ports, right?) &lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at building a client to talk to the newly-minted services. We&amp;rsquo;ll use the &lt;code&gt;RSocketRequester&lt;/code&gt;, a client that we can use to speak to an RSocket endpoint. &lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll need the following dependency:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;RSocket on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-rsocket&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.rpc.client;&#xD;
&#xD;
import lombok.SneakyThrows;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.messaging.rsocket.RSocketRequester;&#xD;
&#xD;
import java.util.Locale;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	@SneakyThrows&#xD;
	public static void main(String[] args) {&#xD;
		System.setProperty(&amp;quot;spring.profiles.active&amp;quot;, &amp;quot;rpcclient&amp;quot;);&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
		Thread.sleep(5_000);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	RSocketRequester rSocketRequester(RSocketRequester.Builder builder) {&#xD;
		return builder.tcp(&amp;quot;localhost&amp;quot;, 8888);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(RSocketRequester rSocketRequester) {&#xD;
		return event -&amp;gt; rSocketRequester //&#xD;
				.route(&amp;quot;greetings.{lang}&amp;quot;, Locale.ENGLISH) //&#xD;
				.data(&amp;quot;World&amp;quot;).retrieveMono(String.class)//&#xD;
				.subscribe(greetings -&amp;gt; System.out.println(&amp;quot;got: &amp;quot; + greetings));&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s what I put into my &lt;code&gt;application.properties&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.main.web-application-type=none
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
  &lt;p&gt;Here, you can see that the default client experience of an RSocket service is more like that of an HTTP endpoint or an exchange with a message queue. We&amp;rsquo;re sending request messages to endpoints, which are more like URIs, not distributed methods. That said, if you &lt;em&gt;really&lt;/em&gt; are all about that RPC life and don&amp;rsquo;t mind an &lt;em&gt;optional&lt;/em&gt; extra dependency. You &lt;em&gt;might&lt;/em&gt; &lt;a href="http://github.com/spring-projects-experimental"&gt;consider the &lt;em&gt;experimental&lt;/em&gt; Spring Retrosocket project&lt;/a&gt;, which we launched to support this use case precisely. It provides a Netflix-feign like RPC experience, but for RSocket. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
</feed>
